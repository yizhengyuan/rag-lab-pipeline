"""
ç®€åŒ–ç‰ˆ Pipeline è°ƒè¯•å·¥å…·
========================

è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆçš„è°ƒè¯•å·¥å…·ï¼Œå¯ä»¥ç‹¬ç«‹è¿è¡Œï¼Œå±•ç¤º Pipeline å„æ­¥éª¤çš„ä¸­é—´ç»“æœã€‚
"""

import os
import json
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import traceback

logger = logging.getLogger(__name__)

class SimplePipelineDebugger:
    """ç®€åŒ–ç‰ˆ Pipeline è°ƒè¯•å™¨"""
    
    def __init__(self, debug_output_dir: str = "./debug_output"):
        """
        åˆå§‹åŒ–è°ƒè¯•å™¨
        
        Args:
            debug_output_dir: è°ƒè¯•è¾“å‡ºç›®å½•
        """
        self.debug_output_dir = debug_output_dir
        
        # åˆ›å»ºè°ƒè¯•è¾“å‡ºç›®å½•
        os.makedirs(debug_output_dir, exist_ok=True)
        
        logger.info(f"ğŸ” ç®€åŒ–ç‰ˆ Pipeline è°ƒè¯•å™¨å·²åˆå§‹åŒ–")
        logger.info(f"ğŸ“ è°ƒè¯•è¾“å‡ºç›®å½•: {debug_output_dir}")
    
    def debug_pipeline_steps(self, file_path: str) -> Dict[str, Any]:
        """
        æ¨¡æ‹Ÿè°ƒè¯• Pipeline å„ä¸ªæ­¥éª¤
        
        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«æ‰€æœ‰è°ƒè¯•ä¿¡æ¯çš„å­—å…¸
        """
        start_time = datetime.now()
        file_name = os.path.basename(file_path)
        base_name = os.path.splitext(file_name)[0]
        
        logger.info(f"ğŸš€ å¼€å§‹è°ƒè¯• Pipeline: {file_path}")
        logger.info("=" * 80)
        
        try:
            # æ¨¡æ‹Ÿå„ä¸ªæ­¥éª¤
            steps_results = {}
            
            # æ­¥éª¤1: æ–‡æ¡£åŠ è½½
            steps_results["document_loading"] = self._simulate_document_loading(file_path)
            
            # æ­¥éª¤2: æ–‡æ¡£åˆ†å—
            steps_results["chunking"] = self._simulate_chunking()
            
            # æ­¥éª¤3: Embedding ç”Ÿæˆ
            steps_results["embedding"] = self._simulate_embedding()
            
            # æ­¥éª¤4: Vector Store æ„å»º
            steps_results["vector_store"] = self._simulate_vector_store()
            
            # æ­¥éª¤5: æ¦‚å¿µæå–
            steps_results["concept_extraction"] = self._simulate_concept_extraction()
            
            # æ­¥éª¤6: æ¦‚å¿µåˆå¹¶
            steps_results["concept_merging"] = self._simulate_concept_merging()
            
            # æ­¥éª¤7: è¯æ®æå–
            steps_results["evidence_extraction"] = self._simulate_evidence_extraction()
            
            # æ­¥éª¤8: æ£€ç´¢æµ‹è¯•
            steps_results["retrieval"] = self._simulate_retrieval()
            
            # æ­¥éª¤9: é—®ç­”ç”Ÿæˆ
            steps_results["qa_generation"] = self._simulate_qa_generation()
            
            # æ±‡æ€»ç»“æœ
            debug_results = {
                "file_info": {
                    "file_path": file_path,
                    "file_name": file_name,
                    "base_name": base_name,
                    "processing_time": (datetime.now() - start_time).total_seconds()
                },
                "step_results": steps_results,
                "timestamp": datetime.now().isoformat()
            }
            
            # ä¿å­˜ç»“æœ
            self._save_debug_results(debug_results, base_name)
            self._generate_debug_report(debug_results, base_name)
            
            logger.info(f"âœ… Pipeline è°ƒè¯•å®Œæˆ: {file_path}")
            return debug_results
            
        except Exception as e:
            logger.error(f"âŒ Pipeline è°ƒè¯•å¤±è´¥: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return {"error": str(e)}
    
    def _simulate_document_loading(self, file_path: str) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ–‡æ¡£åŠ è½½æ­¥éª¤"""
        logger.info("ğŸ“„ æ­¥éª¤1: æ¨¡æ‹Ÿæ–‡æ¡£åŠ è½½...")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            return {
                "success": False,
                "error": f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}",
                "processing_time": 0.1
            }
        
        # è·å–æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(file_path)
        
        result = {
            "success": True,
            "documents_count": 1,
            "file_size_bytes": file_size,
            "estimated_characters": file_size * 2,  # ä¼°ç®—å­—ç¬¦æ•°
            "document_details": [
                {
                    "index": 0,
                    "file_size": file_size,
                    "file_type": os.path.splitext(file_path)[1],
                    "text_preview": f"æ–‡æ¡£: {os.path.basename(file_path)}"
                }
            ],
            "processing_time": 0.5
        }
        
        self._save_step_result("01_document_loading", result)
        logger.info(f"   âœ… æ–‡æ¡£åŠ è½½å®Œæˆ: æ–‡ä»¶å¤§å° {file_size} å­—èŠ‚")
        return result
    
    def _simulate_chunking(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ–‡æ¡£åˆ†å—æ­¥éª¤"""
        logger.info("âœ‚ï¸ æ­¥éª¤2: æ¨¡æ‹Ÿæ–‡æ¡£åˆ†å—...")
        
        # æ¨¡æ‹Ÿåˆ†å—ç»“æœ
        chunks_count = 25
        avg_length = 1500
        
        result = {
            "success": True,
            "chunks_count": chunks_count,
            "chunk_details": [
                {
                    "index": i,
                    "chunk_id": f"chunk_{i:03d}",
                    "text_length": avg_length + (i % 500) - 250,
                    "text_preview": f"è¿™æ˜¯ç¬¬ {i+1} ä¸ªæ–‡æ¡£å—çš„å†…å®¹..."
                }
                for i in range(min(5, chunks_count))  # åªæ˜¾ç¤ºå‰5ä¸ª
            ],
            "chunking_stats": {
                "avg_chunk_length": avg_length,
                "min_chunk_length": avg_length - 250,
                "max_chunk_length": avg_length + 250
            },
            "processing_time": 1.2
        }
        
        self._save_step_result("02_chunking", result)
        logger.info(f"   âœ… æ–‡æ¡£åˆ†å—å®Œæˆ: {chunks_count} ä¸ªå—")
        return result
    
    def _simulate_embedding(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿ Embedding ç”Ÿæˆæ­¥éª¤"""
        logger.info("ğŸ”¢ æ­¥éª¤3: æ¨¡æ‹Ÿ Embedding ç”Ÿæˆ...")
        
        embeddings_count = 25
        dimension = 1536
        
        result = {
            "success": True,
            "embeddings_count": embeddings_count,
            "embedding_details": [
                {
                    "chunk_index": i,
                    "chunk_id": f"chunk_{i:03d}",
                    "embedding_dimension": dimension,
                    "embedding_preview": [0.1, -0.2, 0.3, -0.4, 0.5, -0.6, 0.7, -0.8, 0.9, -1.0],
                    "embedding_norm": 1.0 + (i * 0.1)
                }
                for i in range(min(5, embeddings_count))
            ],
            "embedding_stats": {
                "dimension": dimension,
                "avg_norm": 1.2
            },
            "processing_time": 3.5
        }
        
        self._save_step_result("03_embedding", result)
        logger.info(f"   âœ… Embedding ç”Ÿæˆå®Œæˆ: {embeddings_count} ä¸ªå‘é‡")
        return result
    
    def _simulate_vector_store(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿ Vector Store æ„å»ºæ­¥éª¤"""
        logger.info("ğŸ—„ï¸ æ­¥éª¤4: æ¨¡æ‹Ÿ Vector Store æ„å»º...")
        
        result = {
            "success": True,
            "vector_store_type": "SimpleVectorStore",
            "stored_nodes_count": 25,
            "vector_store_stats": {
                "total_vectors": 25,
                "vector_dimension": 1536
            },
            "processing_time": 0.8
        }
        
        self._save_step_result("04_vector_store", result)
        logger.info(f"   âœ… Vector Store æ„å»ºå®Œæˆ: 25 ä¸ªå‘é‡")
        return result
    
    def _simulate_concept_extraction(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ¦‚å¿µæå–æ­¥éª¤"""
        logger.info("ğŸ§  æ­¥éª¤5: æ¨¡æ‹Ÿæ¦‚å¿µæå–...")
        
        concepts_count = 45
        
        result = {
            "success": True,
            "concepts_count": concepts_count,
            "concept_details": [
                {
                    "chunk_index": i,
                    "chunk_id": f"chunk_{i:03d}",
                    "concepts_count": 2,
                    "concepts": [
                        {
                            "concept_id": f"concept_{i*2+j:03d}",
                            "concept_text": f"æ¦‚å¿µ {i*2+j+1}: ç¤ºä¾‹æ¦‚å¿µå†…å®¹",
                            "confidence": 0.8 + (j * 0.1)
                        }
                        for j in range(2)
                    ]
                }
                for i in range(min(5, 25))
            ],
            "concept_stats": {
                "avg_concepts_per_chunk": 1.8,
                "total_concepts": concepts_count
            },
            "processing_time": 15.3
        }
        
        self._save_step_result("05_concept_extraction", result)
        logger.info(f"   âœ… æ¦‚å¿µæå–å®Œæˆ: {concepts_count} ä¸ªæ¦‚å¿µ")
        return result
    
    def _simulate_concept_merging(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ¦‚å¿µåˆå¹¶æ­¥éª¤"""
        logger.info("ğŸ”— æ­¥éª¤6: æ¨¡æ‹Ÿæ¦‚å¿µåˆå¹¶...")
        
        original_count = 45
        merged_count = 32
        
        result = {
            "success": True,
            "original_concepts_count": original_count,
            "merged_concepts_count": merged_count,
            "merge_stats": {
                "reduction_ratio": (original_count - merged_count) / original_count,
                "concepts_before": original_count,
                "concepts_after": merged_count
            },
            "merge_details": [
                {
                    "concept_id": f"merged_concept_{i:03d}",
                    "concept_text": f"åˆå¹¶æ¦‚å¿µ {i+1}: è¿™æ˜¯ä¸€ä¸ªåˆå¹¶åçš„æ¦‚å¿µ",
                    "source_chunks": [f"chunk_{j:03d}" for j in range(i, min(i+3, 25))],
                    "confidence": 0.85 + (i * 0.01)
                }
                for i in range(min(5, merged_count))
            ],
            "processing_time": 8.7
        }
        
        self._save_step_result("06_concept_merging", result)
        logger.info(f"   âœ… æ¦‚å¿µåˆå¹¶å®Œæˆ: {original_count} -> {merged_count} ä¸ªæ¦‚å¿µ")
        return result
    
    def _simulate_evidence_extraction(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿè¯æ®æå–æ­¥éª¤"""
        logger.info("ğŸ” æ­¥éª¤7: æ¨¡æ‹Ÿè¯æ®æå–...")
        
        evidence_count = 64
        
        result = {
            "success": True,
            "evidence_count": evidence_count,
            "evidence_details": [
                {
                    "concept_id": f"merged_concept_{i:03d}",
                    "concept_text": f"åˆå¹¶æ¦‚å¿µ {i+1}",
                    "evidence_count": 2,
                    "evidence": [
                        {
                            "evidence_id": f"evidence_{i*2+j:03d}",
                            "evidence_text": f"è¯æ® {i*2+j+1}: æ”¯æŒæ¦‚å¿µçš„è¯æ®å†…å®¹",
                            "relevance_score": 0.75 + (j * 0.1)
                        }
                        for j in range(2)
                    ]
                }
                for i in range(min(5, 32))
            ],
            "evidence_stats": {
                "avg_evidence_per_concept": evidence_count / 32,
                "total_evidence": evidence_count
            },
            "processing_time": 12.1
        }
        
        self._save_step_result("07_evidence_extraction", result)
        logger.info(f"   âœ… è¯æ®æå–å®Œæˆ: {evidence_count} ä¸ªè¯æ®")
        return result
    
    def _simulate_retrieval(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿæ£€ç´¢æ­¥éª¤"""
        logger.info("ğŸ¯ æ­¥éª¤8: æ¨¡æ‹Ÿæ£€ç´¢æµ‹è¯•...")
        
        result = {
            "success": True,
            "retrieval_results": [
                {
                    "concept_id": f"merged_concept_{i:03d}",
                    "concept_text": f"åˆå¹¶æ¦‚å¿µ {i+1}",
                    "retrieved_count": 5,
                    "retrieved_chunks": [
                        {
                            "chunk_id": f"chunk_{j:03d}",
                            "chunk_text": f"æ£€ç´¢åˆ°çš„å— {j+1} å†…å®¹",
                            "similarity_score": 0.9 - (j * 0.1)
                        }
                        for j in range(5)
                    ]
                }
                for i in range(3)  # æµ‹è¯•3ä¸ªæ¦‚å¿µ
            ],
            "retrieval_stats": {
                "concepts_tested": 3,
                "avg_retrieved_per_concept": 5.0
            },
            "processing_time": 2.3
        }
        
        self._save_step_result("08_retrieval", result)
        logger.info(f"   âœ… æ£€ç´¢æµ‹è¯•å®Œæˆ: æµ‹è¯•äº† 3 ä¸ªæ¦‚å¿µ")
        return result
    
    def _simulate_qa_generation(self) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿé—®ç­”ç”Ÿæˆæ­¥éª¤"""
        logger.info("â“ æ­¥éª¤9: æ¨¡æ‹Ÿé—®ç­”ç”Ÿæˆ...")
        
        qa_count = 15
        
        result = {
            "success": True,
            "qa_pairs_count": qa_count,
            "qa_details": [
                {
                    "index": i,
                    "question": f"é—®é¢˜ {i+1}: è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹é—®é¢˜ï¼Ÿ",
                    "answer": f"ç­”æ¡ˆ {i+1}: è¿™æ˜¯å¯¹åº”çš„ç¤ºä¾‹ç­”æ¡ˆï¼ŒåŒ…å«äº†è¯¦ç»†çš„è§£é‡Šå’Œè¯´æ˜ã€‚",
                    "question_type": ["factual", "analytical", "conceptual"][i % 3],
                    "difficulty": ["easy", "medium", "hard"][i % 3]
                }
                for i in range(qa_count)
            ],
            "qa_stats": {
                "total_qa_pairs": qa_count,
                "question_types": ["factual", "analytical", "conceptual"],
                "avg_question_length": 25.3,
                "avg_answer_length": 156.7
            },
            "processing_time": 18.9
        }
        
        self._save_step_result("09_qa_generation", result)
        logger.info(f"   âœ… é—®ç­”ç”Ÿæˆå®Œæˆ: {qa_count} ä¸ªé—®ç­”å¯¹")
        return result
    
    def _save_step_result(self, step_name: str, result: Dict[str, Any]):
        """ä¿å­˜æ­¥éª¤ç»“æœåˆ°æ–‡ä»¶"""
        output_path = os.path.join(self.debug_output_dir, f"{step_name}.json")
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"   ğŸ’¾ æ­¥éª¤ç»“æœå·²ä¿å­˜: {output_path}")
    
    def _save_debug_results(self, debug_results: Dict[str, Any], base_name: str):
        """ä¿å­˜å®Œæ•´çš„è°ƒè¯•ç»“æœ"""
        output_path = os.path.join(self.debug_output_dir, f"{base_name}_debug_results.json")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(debug_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ å®Œæ•´è°ƒè¯•ç»“æœå·²ä¿å­˜: {output_path}")
    
    def _generate_debug_report(self, debug_results: Dict[str, Any], base_name: str):
        """ç”Ÿæˆå¯è¯»çš„è°ƒè¯•æŠ¥å‘Š"""
        report_path = os.path.join(self.debug_output_dir, f"{base_name}_debug_report.md")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# Pipeline è°ƒè¯•æŠ¥å‘Š (æ¨¡æ‹Ÿ)\n\n")
            f.write(f"**æ–‡ä»¶**: {debug_results['file_info']['file_name']}\n")
            f.write(f"**å¤„ç†æ—¶é—´**: {debug_results['file_info']['processing_time']:.2f} ç§’\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {debug_results['timestamp']}\n\n")
            
            f.write("## æ­¥éª¤æ¦‚è§ˆ\n\n")
            
            step_names = {
                "document_loading": "ğŸ“„ æ–‡æ¡£åŠ è½½",
                "chunking": "âœ‚ï¸ æ–‡æ¡£åˆ†å—", 
                "embedding": "ğŸ”¢ Embedding ç”Ÿæˆ",
                "vector_store": "ğŸ—„ï¸ Vector Store æ„å»º",
                "concept_extraction": "ğŸ§  æ¦‚å¿µæå–",
                "concept_merging": "ğŸ”— æ¦‚å¿µåˆå¹¶",
                "evidence_extraction": "ğŸ” è¯æ®æå–",
                "retrieval": "ğŸ¯ æ£€ç´¢æµ‹è¯•",
                "qa_generation": "â“ é—®ç­”ç”Ÿæˆ"
            }
            
            for step_key, step_name in step_names.items():
                step_result = debug_results["step_results"].get(step_key, {})
                status = "âœ… æˆåŠŸ" if step_result.get("success", False) else "âŒ å¤±è´¥"
                time_taken = step_result.get("processing_time", 0)
                
                f.write(f"- {step_name}: {status} ({time_taken:.2f}s)\n")
            
            f.write("\n## è¯¦ç»†ç»Ÿè®¡\n\n")
            
            # æ·»åŠ å„æ­¥éª¤çš„è¯¦ç»†ç»Ÿè®¡
            step_results = debug_results["step_results"]
            
            if step_results.get("chunking", {}).get("success"):
                chunk_result = step_results["chunking"]
                f.write(f"### âœ‚ï¸ æ–‡æ¡£åˆ†å—\n")
                f.write(f"- å—æ•°é‡: {chunk_result.get('chunks_count', 0)}\n")
                stats = chunk_result.get('chunking_stats', {})
                f.write(f"- å¹³å‡å—é•¿åº¦: {stats.get('avg_chunk_length', 0):.0f} å­—ç¬¦\n\n")
            
            if step_results.get("concept_extraction", {}).get("success"):
                concept_result = step_results["concept_extraction"]
                f.write(f"### ğŸ§  æ¦‚å¿µæå–\n")
                f.write(f"- æå–æ¦‚å¿µæ•°: {concept_result.get('concepts_count', 0)}\n")
                stats = concept_result.get('concept_stats', {})
                f.write(f"- å¹³å‡æ¯å—æ¦‚å¿µæ•°: {stats.get('avg_concepts_per_chunk', 0):.1f}\n\n")
            
            if step_results.get("concept_merging", {}).get("success"):
                merge_result = step_results["concept_merging"]
                f.write(f"### ğŸ”— æ¦‚å¿µåˆå¹¶\n")
                f.write(f"- åˆå¹¶å‰æ¦‚å¿µæ•°: {merge_result.get('original_concepts_count', 0)}\n")
                f.write(f"- åˆå¹¶åæ¦‚å¿µæ•°: {merge_result.get('merged_concepts_count', 0)}\n")
                stats = merge_result.get('merge_stats', {})
                f.write(f"- å‡å°‘æ¯”ä¾‹: {stats.get('reduction_ratio', 0):.1%}\n\n")
            
            if step_results.get("qa_generation", {}).get("success"):
                qa_result = step_results["qa_generation"]
                f.write(f"### â“ é—®ç­”ç”Ÿæˆ\n")
                f.write(f"- é—®ç­”å¯¹æ•°é‡: {qa_result.get('qa_pairs_count', 0)}\n")
                stats = qa_result.get('qa_stats', {})
                f.write(f"- é—®é¢˜ç±»å‹: {', '.join(stats.get('question_types', []))}\n")
                f.write(f"- å¹³å‡é—®é¢˜é•¿åº¦: {stats.get('avg_question_length', 0):.0f} å­—ç¬¦\n")
                f.write(f"- å¹³å‡ç­”æ¡ˆé•¿åº¦: {stats.get('avg_answer_length', 0):.0f} å­—ç¬¦\n\n")
        
        logger.info(f"ğŸ“Š è°ƒè¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ç®€åŒ–ç‰ˆè°ƒè¯•å™¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ç®€åŒ–ç‰ˆ Pipeline è°ƒè¯•å·¥å…·")
    parser.add_argument("--file", required=True, help="è¦è°ƒè¯•çš„æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", default="./debug_output", help="è°ƒè¯•è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºè°ƒè¯•å™¨
    debugger = SimplePipelineDebugger(debug_output_dir=args.output)
    
    # æ‰§è¡Œè°ƒè¯•
    results = debugger.debug_pipeline_steps(args.file)
    
    if "error" not in results:
        print(f"\nâœ… è°ƒè¯•å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {args.output}")
        print(f"ğŸ“Š æŸ¥çœ‹è°ƒè¯•æŠ¥å‘Š: {args.output}/{os.path.splitext(os.path.basename(args.file))[0]}_debug_report.md")
    else:
        print(f"\nâŒ è°ƒè¯•å¤±è´¥: {results['error']}")


if __name__ == "__main__":
    main() 