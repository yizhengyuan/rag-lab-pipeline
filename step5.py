#!/usr/bin/env python3
"""
æ­¥éª¤5: æ¦‚å¿µæ£€ç´¢ä¸æ˜ å°„ - å¢å¼ºç‰ˆ
===============================

åŠŸèƒ½ï¼š
1. ä»æ­¥éª¤4çš„ç»“æœä¸­è¯»å–åˆå¹¶åçš„æ¦‚å¿µ
2. ä»æ­¥éª¤2çš„ç»“æœä¸­é‡å»ºåˆ†å—æ•°æ®
3. æ‰§è¡Œæ¦‚å¿µåˆ°åˆ†å—çš„æ™ºèƒ½æ£€ç´¢
4. è®¡ç®—ç›¸ä¼¼åº¦å’Œç›¸å…³æ€§åˆ†æ•°
5. ä¿å­˜åˆ°åŒä¸€ä¸ªå®éªŒæ–‡ä»¶å¤¹

ç”¨æ³•: 
- python step5.py <step4è¾“å‡ºæ–‡ä»¶.txt>
- python step5.py <å®éªŒæ–‡ä»¶å¤¹è·¯å¾„>

æ–°åŠŸèƒ½ï¼š
- âœ… è‡ªåŠ¨è¯†åˆ«å¹¶ä½¿ç”¨step4çš„å®éªŒæ–‡ä»¶å¤¹
- âœ… æ™ºèƒ½æ¦‚å¿µåˆ°åˆ†å—çš„æ£€ç´¢ç®—æ³•
- âœ… å¤šç»´åº¦ç›¸ä¼¼åº¦è®¡ç®—å’Œè¯„åˆ†
- âœ… ç»Ÿä¸€çš„å®éªŒç®¡ç†
- âœ… æ£€ç´¢ç»“æœè´¨é‡è¯„ä¼°
"""

import sys
import json
import time
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Set, Tuple
from collections import defaultdict
import logging
import numpy as np

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
sys.path.append(str(Path(__file__).parent))
from llama_index.core import Document, VectorStoreIndex
from llama_index.core.schema import TextNode

# å¯¼å…¥æ ¸å¿ƒå¤„ç†æ¨¡å—
from config.settings import load_config_from_yaml
from core.nodes import ConceptNode

# å¯¼å…¥å®éªŒç®¡ç†å™¨
from utils.experiment_manager import ExperimentManager
from utils.helpers import FileHelper

logger = logging.getLogger(__name__)

def load_step4_result(step4_file_or_dir: str) -> tuple:
    """
    ä»æ­¥éª¤4çš„è¾“å‡ºæ–‡ä»¶æˆ–å®éªŒæ–‡ä»¶å¤¹ä¸­åŠ è½½ç»“æœ
    
    Args:
        step4_file_or_dir: æ­¥éª¤4çš„è¾“å‡ºæ–‡ä»¶æˆ–å®éªŒæ–‡ä»¶å¤¹è·¯å¾„
        
    Returns:
        tuple: (step4_result, experiment_manager)
    """
    step4_path = Path(step4_file_or_dir)
    
    if step4_path.is_file():
        # æƒ…å†µ1ï¼šç›´æ¥æŒ‡å®šäº†step4çš„è¾“å‡ºæ–‡ä»¶
        if step4_path.name.startswith("step4") and step4_path.suffix == ".txt":
            experiment_dir = step4_path.parent
            experiment_manager = ExperimentManager.load_experiment(str(experiment_dir))
            
            # ä»txtæ–‡ä»¶åŠ è½½ç»“æœ
            step4_result = load_result_from_txt(str(step4_path))
            
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {step4_path}")
            
    elif step4_path.is_dir():
        # æƒ…å†µ2ï¼šç›´æ¥æŒ‡å®šäº†å®éªŒæ–‡ä»¶å¤¹
        experiment_manager = ExperimentManager.load_experiment(str(step4_path))
        
        # æŸ¥æ‰¾step4çš„è¾“å‡ºæ–‡ä»¶
        step4_txt_path = experiment_manager.get_step_output_path(4, "txt")
        if not step4_txt_path.exists():
            raise FileNotFoundError(f"å®éªŒæ–‡ä»¶å¤¹ä¸­æ‰¾ä¸åˆ°step4è¾“å‡ºæ–‡ä»¶: {step4_txt_path}")
        
        step4_result = load_result_from_txt(str(step4_txt_path))
        
    else:
        raise FileNotFoundError(f"è¾“å…¥è·¯å¾„ä¸å­˜åœ¨: {step4_path}")
    
    return step4_result, experiment_manager

def load_result_from_txt(input_file: str) -> Dict[str, Any]:
    """ä»txtæ–‡ä»¶ä¸­åŠ è½½ç»“æœæ•°æ®"""
    with open(input_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    start_marker = "# JSON_DATA_START\n"
    end_marker = "\n# JSON_DATA_END"
    
    start_idx = content.find(start_marker)
    end_idx = content.find(end_marker)
    
    if start_idx == -1 or end_idx == -1:
        raise ValueError("æ— æ³•ä»txtæ–‡ä»¶ä¸­è§£ææ•°æ®")
    
    json_str = content[start_idx + len(start_marker):end_idx]
    return json.loads(json_str)

def load_previous_steps_data(experiment_manager: ExperimentManager) -> Dict[str, Any]:
    """
    åŠ è½½ä¹‹å‰æ­¥éª¤çš„æ•°æ®
    
    Args:
        experiment_manager: å®éªŒç®¡ç†å™¨
        
    Returns:
        Dict[str, Any]: åŒ…å«ä¹‹å‰æ­¥éª¤æ•°æ®çš„å­—å…¸
    """
    previous_data = {}
    
    # åŠ è½½æ­¥éª¤2çš„æ•°æ®ï¼ˆéœ€è¦åˆ†å—ä¿¡æ¯ï¼‰
    step2_path = experiment_manager.get_step_output_path(2, "txt")
    if step2_path.exists():
        try:
            step2_result = load_result_from_txt(str(step2_path))
            previous_data["step2"] = step2_result
            print(f"âœ… åŠ è½½æ­¥éª¤2æ•°æ®: {step2_path}")
        except Exception as e:
            print(f"âš ï¸ åŠ è½½æ­¥éª¤2æ•°æ®å¤±è´¥: {e}")
    
    return previous_data

def extract_concept_nodes_from_step4(step4_result: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ä»æ­¥éª¤4ç»“æœä¸­æå–æ¦‚å¿µèŠ‚ç‚¹
    
    Args:
        step4_result: æ­¥éª¤4çš„ç»“æœ
        
    Returns:
        List[Dict[str, Any]]: æ¦‚å¿µèŠ‚ç‚¹åˆ—è¡¨
    """
    print("ğŸ“Š ä»æ­¥éª¤4ç»“æœä¸­æå–æ¦‚å¿µèŠ‚ç‚¹...")
    
    concept_nodes = step4_result.get("concept_nodes", [])
    
    if not concept_nodes:
        raise ValueError("æ­¥éª¤4ç»“æœä¸­æ²¡æœ‰æ‰¾åˆ°æ¦‚å¿µèŠ‚ç‚¹æ•°æ®")
    
    print(f"   - æ¦‚å¿µèŠ‚ç‚¹æ•°: {len(concept_nodes)}")
    
    # éªŒè¯æ¦‚å¿µèŠ‚ç‚¹æ ¼å¼
    valid_concepts = []
    for concept in concept_nodes:
        if isinstance(concept, dict) and "concept_text" in concept:
            valid_concepts.append(concept)
        else:
            print(f"âš ï¸ è·³è¿‡æ— æ•ˆçš„æ¦‚å¿µèŠ‚ç‚¹: {type(concept)}")
    
    print(f"   - æœ‰æ•ˆæ¦‚å¿µèŠ‚ç‚¹æ•°: {len(valid_concepts)}")
    
    return valid_concepts

def reconstruct_chunks_from_step2(step2_result: Dict[str, Any]) -> List[TextNode]:
    """
    ä»æ­¥éª¤2ç»“æœé‡å»ºTextNodeå¯¹è±¡
    
    Args:
        step2_result: æ­¥éª¤2çš„ç»“æœ
        
    Returns:
        List[TextNode]: åˆ†å—èŠ‚ç‚¹åˆ—è¡¨
    """
    print("ğŸ”„ ä»æ­¥éª¤2ç»“æœä¸­é‡å»ºåˆ†å—æ•°æ®...")
    
    # å°è¯•ä¸åŒçš„å­—æ®µåï¼ˆå…¼å®¹æ€§ï¼‰
    chunks_data = None
    for field_name in ["chunks", "chunk_nodes", "processed_chunks"]:
        if field_name in step2_result:
            chunks_data = step2_result[field_name]
            print(f"âœ… æ‰¾åˆ°åˆ†å—æ•°æ®å­—æ®µ: {field_name}")
            break
    
    if not chunks_data:
        available_fields = list(step2_result.keys())
        print(f"âŒ æœªæ‰¾åˆ°åˆ†å—æ•°æ®ï¼Œå¯ç”¨å­—æ®µ: {available_fields}")
        raise ValueError("æ­¥éª¤2ç»“æœä¸­æ²¡æœ‰æ‰¾åˆ°åˆ†å—æ•°æ®")
    
    # é‡å»ºTextNodeå¯¹è±¡
    chunk_nodes = []
    for i, chunk_data in enumerate(chunks_data):
        try:
            if isinstance(chunk_data, dict):
                # ä»å­—å…¸æ•°æ®é‡å»ºTextNode
                text_node = TextNode(
                    text=chunk_data.get("text", ""),
                    metadata=chunk_data.get("metadata", {})
                )
                
                # è®¾ç½®node_id
                if "node_id" in chunk_data:
                    text_node.node_id = chunk_data["node_id"]
                
                chunk_nodes.append(text_node)
                
            elif hasattr(chunk_data, 'text'):
                # å·²ç»æ˜¯TextNodeå¯¹è±¡
                chunk_nodes.append(chunk_data)
                
            else:
                print(f"âš ï¸ è·³è¿‡æ— æ•ˆçš„chunkæ•°æ®: {type(chunk_data)}")
                continue
                
        except Exception as e:
            print(f"âš ï¸ é‡å»ºchunk {i} å¤±è´¥: {e}")
            continue
    
    print(f"âœ… æˆåŠŸé‡å»º {len(chunk_nodes)} ä¸ªTextNodeå¯¹è±¡")
    return chunk_nodes

def calculate_concept_chunk_similarity(concept_text: str, chunk_text: str, chunk_concepts: List[str] = None) -> float:
    """
    è®¡ç®—æ¦‚å¿µä¸åˆ†å—çš„ç›¸ä¼¼åº¦
    
    Args:
        concept_text: æ¦‚å¿µæ–‡æœ¬
        chunk_text: åˆ†å—æ–‡æœ¬
        chunk_concepts: åˆ†å—ä¸­çš„æ¦‚å¿µåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        float: ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
    """
    from difflib import SequenceMatcher
    
    # 1. ç›´æ¥æ–‡æœ¬ç›¸ä¼¼åº¦
    text_similarity = SequenceMatcher(None, concept_text.lower(), chunk_text.lower()).ratio()
    
    # 2. å…³é”®è¯åŒ¹é…åº¦
    concept_words = set(concept_text.lower().split())
    chunk_words = set(chunk_text.lower().split())
    
    if concept_words and chunk_words:
        keyword_overlap = len(concept_words.intersection(chunk_words)) / len(concept_words.union(chunk_words))
    else:
        keyword_overlap = 0.0
    
    # 3. æ¦‚å¿µåŒ…å«åº¦ï¼ˆå¦‚æœæœ‰chunkçš„æ¦‚å¿µä¿¡æ¯ï¼‰
    concept_containment = 0.0
    if chunk_concepts:
        chunk_concepts_lower = [c.lower() for c in chunk_concepts]
        if any(concept_text.lower() in cc or cc in concept_text.lower() for cc in chunk_concepts_lower):
            concept_containment = 0.5
    
    # 4. é•¿åº¦ç›¸å…³æ€§è°ƒæ•´
    length_factor = min(len(concept_text), len(chunk_text)) / max(len(concept_text), len(chunk_text), 1)
    
    # ç»¼åˆç›¸ä¼¼åº¦è®¡ç®—
    final_similarity = (
        text_similarity * 0.3 +
        keyword_overlap * 0.4 +
        concept_containment * 0.2 +
        length_factor * 0.1
    )
    
    return min(1.0, max(0.0, final_similarity))

def perform_concept_retrieval(concept_nodes: List[Dict[str, Any]], 
                            chunk_nodes: List[TextNode],
                            config) -> Dict[str, Any]:
    """
    æ‰§è¡Œæ¦‚å¿µæ£€ç´¢
    
    Args:
        concept_nodes: æ¦‚å¿µèŠ‚ç‚¹åˆ—è¡¨
        chunk_nodes: åˆ†å—èŠ‚ç‚¹åˆ—è¡¨
        config: é…ç½®å¯¹è±¡
        
    Returns:
        Dict[str, Any]: æ£€ç´¢ç»“æœ
    """
    print("ğŸ” å¼€å§‹æ‰§è¡Œæ¦‚å¿µæ£€ç´¢...")
    
    top_k = config.get("retrieval.top_k", 5)
    similarity_threshold = config.get("retrieval.similarity_cutoff", 0.1)
    
    retrieval_results = {}
    total_retrievals = 0
    concepts_with_retrievals = 0
    all_similarities = []
    
    for concept in concept_nodes:
        concept_id = concept.get("concept_id", "unknown")
        concept_text = concept.get("concept_text", "")
        
        print(f"   æ£€ç´¢æ¦‚å¿µ: {concept_text}")
        
        # ä¸ºå½“å‰æ¦‚å¿µæ£€ç´¢ç›¸å…³åˆ†å—
        chunk_similarities = []
        
        for chunk in chunk_nodes:
            # è·å–åˆ†å—çš„æ¦‚å¿µä¿¡æ¯
            chunk_concepts = []
            concepts_data = chunk.metadata.get("concepts", "[]")
            if isinstance(concepts_data, str):
                try:
                    chunk_concepts = json.loads(concepts_data)
                except:
                    pass
            elif isinstance(concepts_data, list):
                chunk_concepts = concepts_data
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarity = calculate_concept_chunk_similarity(
                concept_text, 
                chunk.text, 
                chunk_concepts
            )
            
            if similarity >= similarity_threshold:
                chunk_similarities.append({
                    "chunk_id": chunk.metadata.get("chunk_id", chunk.node_id),
                    "chunk_text": chunk.text,
                    "chunk_concepts": chunk_concepts,
                    "similarity_score": similarity,
                    "node_id": chunk.node_id
                })
        
        # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶å–å‰kä¸ª
        chunk_similarities.sort(key=lambda x: x["similarity_score"], reverse=True)
        top_chunks = chunk_similarities[:top_k]
        
        # ç»Ÿè®¡ä¿¡æ¯
        retrieval_count = len(top_chunks)
        avg_similarity = sum(c["similarity_score"] for c in top_chunks) / len(top_chunks) if top_chunks else 0
        
        all_similarities.extend([c["similarity_score"] for c in top_chunks])
        total_retrievals += retrieval_count
        
        if retrieval_count > 0:
            concepts_with_retrievals += 1
        
        # ä¿å­˜æ£€ç´¢ç»“æœ
        retrieval_results[concept_id] = {
            "concept_text": concept_text,
            "concept_id": concept_id,
            "retrieval_count": retrieval_count,
            "avg_similarity": avg_similarity,
            "max_similarity": max([c["similarity_score"] for c in top_chunks]) if top_chunks else 0,
            "min_similarity": min([c["similarity_score"] for c in top_chunks]) if top_chunks else 0,
            "retrieved_chunks": top_chunks,
            "source_chunks": concept.get("source_chunks", []),
            "confidence_score": concept.get("confidence_score", 0)
        }
    
    # è®¡ç®—å…¨å±€ç»Ÿè®¡
    avg_similarity_all = sum(all_similarities) / len(all_similarities) if all_similarities else 0
    avg_retrievals_per_concept = total_retrievals / len(concept_nodes) if concept_nodes else 0
    
    print(f"   âœ… æ£€ç´¢å®Œæˆ:")
    print(f"      - æ€»æ£€ç´¢ç»“æœ: {total_retrievals}")
    print(f"      - æœ‰ç»“æœçš„æ¦‚å¿µ: {concepts_with_retrievals}/{len(concept_nodes)}")
    print(f"      - å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity_all:.4f}")
    
    return {
        "retrieval_results": retrieval_results,
        "statistics": {
            "concept_count": len(concept_nodes),
            "chunk_count": len(chunk_nodes),
            "total_retrievals": total_retrievals,
            "concepts_with_retrievals": concepts_with_retrievals,
            "avg_retrievals_per_concept": avg_retrievals_per_concept,
            "avg_similarity_all": avg_similarity_all,
            "retrieval_coverage": concepts_with_retrievals / len(concept_nodes) if concept_nodes else 0,
            "top_k": top_k,
            "similarity_threshold": similarity_threshold
        }
    }

def analyze_retrieval_quality(retrieval_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    åˆ†ææ£€ç´¢è´¨é‡
    
    Args:
        retrieval_data: æ£€ç´¢æ•°æ®
        
    Returns:
        Dict[str, Any]: è´¨é‡åˆ†æç»“æœ
    """
    print("ğŸ“ˆ åˆ†ææ£€ç´¢è´¨é‡...")
    
    retrieval_results = retrieval_data["retrieval_results"]
    
    # è´¨é‡æŒ‡æ ‡è®¡ç®—
    high_quality_retrievals = 0  # ç›¸ä¼¼åº¦ > 0.5
    medium_quality_retrievals = 0  # ç›¸ä¼¼åº¦ 0.2-0.5
    low_quality_retrievals = 0  # ç›¸ä¼¼åº¦ < 0.2
    
    concept_coverage_scores = []
    similarity_distributions = {"0.0-0.2": 0, "0.2-0.4": 0, "0.4-0.6": 0, "0.6-0.8": 0, "0.8-1.0": 0}
    
    for concept_id, result in retrieval_results.items():
        avg_sim = result["avg_similarity"]
        retrieval_count = result["retrieval_count"]
        
        # æ¦‚å¿µè¦†ç›–åº¦è¯„åˆ†
        if retrieval_count >= 3 and avg_sim >= 0.3:
            coverage_score = 1.0
        elif retrieval_count >= 2 and avg_sim >= 0.2:
            coverage_score = 0.7
        elif retrieval_count >= 1 and avg_sim >= 0.1:
            coverage_score = 0.4
        else:
            coverage_score = 0.0
        
        concept_coverage_scores.append(coverage_score)
        
        # è´¨é‡åˆ†ç±»
        if avg_sim >= 0.5:
            high_quality_retrievals += 1
        elif avg_sim >= 0.2:
            medium_quality_retrievals += 1
        else:
            low_quality_retrievals += 1
        
        # ç›¸ä¼¼åº¦åˆ†å¸ƒ
        for chunk in result["retrieved_chunks"]:
            sim = chunk["similarity_score"]
            if sim >= 0.8:
                similarity_distributions["0.8-1.0"] += 1
            elif sim >= 0.6:
                similarity_distributions["0.6-0.8"] += 1
            elif sim >= 0.4:
                similarity_distributions["0.4-0.6"] += 1
            elif sim >= 0.2:
                similarity_distributions["0.2-0.4"] += 1
            else:
                similarity_distributions["0.0-0.2"] += 1
    
    # æ•´ä½“è´¨é‡è¯„åˆ†
    total_concepts = len(retrieval_results)
    avg_coverage_score = sum(concept_coverage_scores) / len(concept_coverage_scores) if concept_coverage_scores else 0
    
    quality_score = (
        (high_quality_retrievals / total_concepts * 1.0) +
        (medium_quality_retrievals / total_concepts * 0.6) +
        (low_quality_retrievals / total_concepts * 0.2)
    ) if total_concepts > 0 else 0
    
    return {
        "overall_quality_score": quality_score,
        "avg_coverage_score": avg_coverage_score,
        "quality_distribution": {
            "high_quality": high_quality_retrievals,
            "medium_quality": medium_quality_retrievals,
            "low_quality": low_quality_retrievals
        },
        "similarity_distribution": similarity_distributions,
        "top_performing_concepts": sorted(
            [(cid, res["avg_similarity"], res["retrieval_count"]) 
             for cid, res in retrieval_results.items()],
            key=lambda x: x[1], reverse=True
        )[:10]
    }

def process_step5_concept_retrieval(step4_result: Dict[str, Any], 
                                   previous_data: Dict[str, Any],
                                   config_path: str = "config.yml") -> Dict[str, Any]:
    """
    æ‰§è¡Œæ­¥éª¤5çš„æ¦‚å¿µæ£€ç´¢å¤„ç†
    
    Args:
        step4_result: æ­¥éª¤4çš„ç»“æœ
        previous_data: ä¹‹å‰æ­¥éª¤çš„æ•°æ®
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        Dict[str, Any]: æ­¥éª¤5çš„å¤„ç†ç»“æœ
    """
    start_time = time.time()
    
    try:
        # 1. åŠ è½½é…ç½®
        print("ğŸ“‹ åŠ è½½é…ç½®...")
        config = load_config_from_yaml(config_path)
        
        # 2. æå–æ¦‚å¿µèŠ‚ç‚¹
        print("ğŸ“Š æå–æ¦‚å¿µèŠ‚ç‚¹...")
        concept_nodes = extract_concept_nodes_from_step4(step4_result)
        
        # 3. é‡å»ºåˆ†å—æ•°æ®
        print("ğŸ”„ é‡å»ºåˆ†å—æ•°æ®...")
        if "step2" not in previous_data:
            raise ValueError("ç¼ºå°‘æ­¥éª¤2çš„åˆ†å—æ•°æ®")
        
        chunk_nodes = reconstruct_chunks_from_step2(previous_data["step2"])
        
        # 4. æ‰§è¡Œæ¦‚å¿µæ£€ç´¢
        print("ğŸ” æ‰§è¡Œæ¦‚å¿µæ£€ç´¢...")
        retrieval_data = perform_concept_retrieval(concept_nodes, chunk_nodes, config)
        
        # 5. åˆ†ææ£€ç´¢è´¨é‡
        print("ğŸ“ˆ åˆ†ææ£€ç´¢è´¨é‡...")
        quality_analysis = analyze_retrieval_quality(retrieval_data)
        
        processing_time = time.time() - start_time
        
        # 6. æ„å»ºç»“æœ
        result = {
            "success": True,
            "step": 5,
            "step_name": "æ¦‚å¿µæ£€ç´¢ä¸æ˜ å°„",
            "retrieval_results": retrieval_data["retrieval_results"],
            "statistics": retrieval_data["statistics"],
            "quality_analysis": quality_analysis,
            "processing_time": processing_time,
            "timestamp": datetime.now().isoformat(),
            "config_used": {
                "top_k": config.get("retrieval.top_k", 5),
                "similarity_threshold": config.get("retrieval.similarity_cutoff", 0.1)
            }
        }
        
        return result
        
    except Exception as e:
        error_msg = f"æ­¥éª¤5å¤„ç†å¤±è´¥: {str(e)}"
        print(f"âŒ {error_msg}")
        
        result = {
            "success": False,
            "step": 5,
            "step_name": "æ¦‚å¿µæ£€ç´¢ä¸æ˜ å°„",
            "error": error_msg,
            "processing_time": time.time() - start_time,
            "timestamp": datetime.now().isoformat()
        }
        
        return result

def main():
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python step5.py <step4è¾“å‡ºæ–‡ä»¶æˆ–å®éªŒæ–‡ä»¶å¤¹>")
        print("ç¤ºä¾‹:")
        print("  python step5.py experiments/20241204_143052_attention_paper/step4_reranking.txt")
        print("  python step5.py experiments/20241204_143052_attention_paper/")
        print("\næ–°åŠŸèƒ½:")
        print("âœ… è‡ªåŠ¨è¯†åˆ«å®éªŒæ–‡ä»¶å¤¹")
        print("âœ… æ™ºèƒ½æ¦‚å¿µåˆ°åˆ†å—çš„æ£€ç´¢ç®—æ³•")
        print("âœ… å¤šç»´åº¦ç›¸ä¼¼åº¦è®¡ç®—å’Œè¯„åˆ†")
        print("âœ… ç»Ÿä¸€çš„å®éªŒç®¡ç†")
        sys.exit(1)
    
    input_path = sys.argv[1]
    
    print(f"ğŸš€ æ­¥éª¤5: æ¦‚å¿µæ£€ç´¢ä¸æ˜ å°„ (å¢å¼ºç‰ˆ)")
    print(f"ğŸ“„ è¾“å…¥: {input_path}")
    print("="*60)
    
    try:
        # 1. åŠ è½½æ­¥éª¤4ç»“æœå’Œå®éªŒç®¡ç†å™¨
        print("ğŸ“‚ åŠ è½½æ­¥éª¤4ç»“æœ...")
        step4_result, experiment_manager = load_step4_result(input_path)
        
        if not step4_result.get("success"):
            print("âŒ æ­¥éª¤4æœªæˆåŠŸå®Œæˆï¼Œæ— æ³•ç»§ç»­")
            sys.exit(1)
        
        print(f"âœ… å·²åŠ è½½å®éªŒ: {experiment_manager.experiment_name}")
        print(f"ğŸ“ å®éªŒç›®å½•: {experiment_manager.experiment_dir}")
        print()
        
        # 2. åŠ è½½ä¹‹å‰æ­¥éª¤çš„æ•°æ®
        print("ğŸ“‚ åŠ è½½ä¹‹å‰æ­¥éª¤çš„æ•°æ®...")
        previous_data = load_previous_steps_data(experiment_manager)
        
        # 3. æ‰§è¡Œæ­¥éª¤5å¤„ç†
        print("ğŸ”„ å¼€å§‹æ­¥éª¤5å¤„ç†...")
        result = process_step5_concept_retrieval(step4_result, previous_data)
        
        # 4. ä¿å­˜ç»“æœåˆ°å®éªŒæ–‡ä»¶å¤¹
        print("ğŸ’¾ ä¿å­˜å®éªŒç»“æœ...")
        saved_files = experiment_manager.save_step_result(
            step_num=5,
            result=result,
            save_formats=['txt', 'json']
        )
        
        if result.get("success"):
            print(f"\nâœ… æ­¥éª¤5å®Œæˆ!")
            print(f"ğŸ“ å®éªŒç›®å½•: {experiment_manager.experiment_dir}")
            print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶:")
            for format_type, file_path in saved_files.items():
                print(f"   - {format_type.upper()}: {file_path}")
            
            # æ˜¾ç¤ºå¤„ç†ç»“æœæ‘˜è¦
            stats = result.get("statistics", {})
            quality = result.get("quality_analysis", {})
            
            print(f"\nğŸ“Š æ¦‚å¿µæ£€ç´¢ç»“æœæ‘˜è¦:")
            print(f"   - æ¦‚å¿µæ•°é‡: {stats.get('concept_count', 0)}")
            print(f"   - åˆ†å—æ•°é‡: {stats.get('chunk_count', 0)}")
            print(f"   - æ€»æ£€ç´¢ç»“æœ: {stats.get('total_retrievals', 0)}")
            print(f"   - æœ‰ç»“æœçš„æ¦‚å¿µ: {stats.get('concepts_with_retrievals', 0)}")
            print(f"   - æ£€ç´¢è¦†ç›–ç‡: {stats.get('retrieval_coverage', 0):.2%}")
            print(f"   - å¹³å‡ç›¸ä¼¼åº¦: {stats.get('avg_similarity_all', 0):.4f}")
            print(f"   - å¹³å‡æ¯æ¦‚å¿µæ£€ç´¢æ•°: {stats.get('avg_retrievals_per_concept', 0):.2f}")
            print(f"   - å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f} ç§’")
            
            # æ˜¾ç¤ºè´¨é‡åˆ†æ
            print(f"\nğŸ“ˆ æ£€ç´¢è´¨é‡åˆ†æ:")
            print(f"   - æ•´ä½“è´¨é‡è¯„åˆ†: {quality.get('overall_quality_score', 0):.3f}")
            print(f"   - å¹³å‡è¦†ç›–åº¦: {quality.get('avg_coverage_score', 0):.3f}")
            
            quality_dist = quality.get("quality_distribution", {})
            print(f"   - é«˜è´¨é‡æ£€ç´¢: {quality_dist.get('high_quality', 0)} ä¸ª")
            print(f"   - ä¸­ç­‰è´¨é‡æ£€ç´¢: {quality_dist.get('medium_quality', 0)} ä¸ª")
            print(f"   - ä½è´¨é‡æ£€ç´¢: {quality_dist.get('low_quality', 0)} ä¸ª")
            
            # æ˜¾ç¤ºé¡¶çº§æ£€ç´¢ç»“æœ
            top_concepts = quality.get("top_performing_concepts", [])
            if top_concepts:
                print(f"\nğŸŒŸ é¡¶çº§æ£€ç´¢ç»“æœ (å‰5ä¸ª):")
                for i, (concept_id, avg_sim, count) in enumerate(top_concepts[:5], 1):
                    retrieval_results = result.get("retrieval_results", {})
                    concept_text = retrieval_results.get(concept_id, {}).get("concept_text", "æœªçŸ¥")
                    print(f"   {i}. {concept_text}")
                    print(f"      ç›¸ä¼¼åº¦: {avg_sim:.4f}, æ£€ç´¢æ•°: {count}")
            
            # æ˜¾ç¤ºå®éªŒçŠ¶æ€
            summary = experiment_manager.get_experiment_summary()
            print(f"\nğŸ§ª å®éªŒçŠ¶æ€:")
            print(f"   - å®éªŒID: {summary['experiment_id']}")
            print(f"   - å·²å®Œæˆæ­¥éª¤: {summary['steps_completed']}/{summary['total_steps']}")
            print(f"   - å½“å‰çŠ¶æ€: {summary['status']}")
            
            # æç¤ºåç»­æ­¥éª¤
            print(f"\nğŸ“‹ åç»­æ­¥éª¤:")
            print(f"   è¿è¡Œä¸‹ä¸€æ­¥: python step6.py {saved_files['txt']}")
            print(f"   æŸ¥çœ‹ç»“æœ: cat {saved_files['txt']}")
            print(f"   æŸ¥çœ‹æ£€ç´¢: grep -A 10 'é¡¶çº§æ£€ç´¢ç»“æœ' {saved_files['txt']}")
                
        else:
            print(f"âŒ æ­¥éª¤5å¤±è´¥: {result.get('error')}")
            
            # å³ä½¿å¤±è´¥ä¹Ÿä¿å­˜é”™è¯¯ä¿¡æ¯
            experiment_manager.save_step_result(
                step_num=5,
                result=result,
                save_formats=['txt']
            )
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        # å¦‚æœæœ‰å®éªŒç®¡ç†å™¨ï¼Œä¿å­˜é”™è¯¯ä¿¡æ¯
        if 'experiment_manager' in locals():
            error_result = {
                "step": 5,
                "step_name": "æ¦‚å¿µæ£€ç´¢ä¸æ˜ å°„",
                "success": False,
                "error": str(e),
                "traceback": traceback.format_exc(),
                "processing_time": 0.0,
                "timestamp": datetime.now().isoformat()
            }
            
            try:
                experiment_manager.save_step_result(5, error_result, ['txt'])
                print(f"ğŸ“„ é”™è¯¯ä¿¡æ¯å·²ä¿å­˜åˆ°å®éªŒç›®å½•: {experiment_manager.experiment_dir}")
            except:
                pass
        
        sys.exit(1)

if __name__ == "__main__":
    main()