#!/usr/bin/env python3
"""
æ­¥éª¤5: æ¦‚å¿µæ£€ç´¢ - åŸºäºpipeline0604.py
================

ç”¨æ³•: python step5.py step4Out.txt
"""

import sys
import json
from pathlib import Path
from datetime import datetime

# å¯¼å…¥ç°æœ‰çš„å¤„ç†å™¨ç±»
sys.path.append(str(Path(__file__).parent))
from pipeline0604 import StepByStepPipelineProcessor

def save_result_as_txt(result, output_file):
    """ä¿å­˜ç»“æœä¸ºtxtæ ¼å¼"""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("æ­¥éª¤5: æ¦‚å¿µæ£€ç´¢ - å¤„ç†ç»“æœ\n")
        f.write("="*80 + "\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"å¤„ç†çŠ¶æ€: {'âœ… æˆåŠŸ' if result.get('success') else 'âŒ å¤±è´¥'}\n")
        
        if result.get("success"):
            stats = result.get("statistics", {})
            
            f.write(f"\nğŸ“Š æ¦‚å¿µæ£€ç´¢ç»Ÿè®¡:\n")
            f.write(f"- æ¦‚å¿µæ•°é‡: {stats.get('concept_count', 0)}\n")
            f.write(f"- åˆ†å—æ•°é‡: {stats.get('chunk_count', 0)}\n")
            f.write(f"- æ€»æ£€ç´¢ç»“æœ: {stats.get('total_retrievals', 0)}\n")
            f.write(f"- å¹³å‡æ¯æ¦‚å¿µæ£€ç´¢æ•°: {stats.get('avg_retrievals_per_concept', 0):.2f}\n")
            f.write(f"- æœ‰æ£€ç´¢ç»“æœçš„æ¦‚å¿µ: {stats.get('concepts_with_retrievals', 0)}/{stats.get('concept_count', 0)}\n")
            f.write(f"- å¹³å‡ç›¸ä¼¼åº¦: {stats.get('avg_similarity_all', 0):.4f}\n")
            f.write(f"- å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f} ç§’\n")
            
            # æ˜¾ç¤ºæ£€ç´¢ç»“æœè¯¦æƒ…
            retrieval_results = result.get("retrieval_results", {})
            f.write(f"\nğŸ” æ¦‚å¿µæ£€ç´¢è¯¦ç»†ç»“æœ:\n")
            f.write("-" * 80 + "\n")
            
            for i, (concept_id, retrieval_data) in enumerate(retrieval_results.items(), 1):
                concept_text = retrieval_data.get("concept_text", "æœªçŸ¥")
                retrieval_count = retrieval_data.get("retrieval_count", 0)
                avg_similarity = retrieval_data.get("avg_similarity", 0)
                
                f.write(f"\næ¦‚å¿µ {i}: {concept_text}\n")
                f.write(f"  æ¦‚å¿µID: {concept_id}\n")
                f.write(f"  æ£€ç´¢åˆ°ç›¸å…³åˆ†å—æ•°: {retrieval_count}\n")
                f.write(f"  å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.4f}\n")
                
                retrieved_chunks = retrieval_data.get("retrieved_chunks", [])
                for j, chunk in enumerate(retrieved_chunks[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                    f.write(f"    ç›¸å…³åˆ†å— {j}:\n")
                    f.write(f"      ID: {chunk.get('chunk_id', 'æœªçŸ¥')}\n")
                    f.write(f"      ç›¸ä¼¼åº¦: {chunk.get('similarity_score', 0):.4f}\n")
                    f.write(f"      å†…å®¹: {chunk.get('chunk_text', '')[:80]}...\n")
                
                if len(retrieved_chunks) > 3:
                    f.write(f"    ... è¿˜æœ‰ {len(retrieved_chunks) - 3} ä¸ªç›¸å…³åˆ†å—\n")
                
                f.write("-" * 60 + "\n")
                
        else:
            f.write(f"\nâŒ é”™è¯¯ä¿¡æ¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}\n")
        
        # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ æœºå™¨å¯è¯»çš„æ•°æ®
        f.write(f"\n" + "="*80 + "\n")
        f.write("# æœºå™¨å¯è¯»æ•°æ® (è¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹)\n")
        f.write("# JSON_DATA_START\n")
        f.write(json.dumps(result, ensure_ascii=False, indent=2))
        f.write("\n# JSON_DATA_END\n")

def load_result_from_txt(input_file):
    """ä»txtæ–‡ä»¶ä¸­åŠ è½½ç»“æœæ•°æ®"""
    with open(input_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    start_marker = "# JSON_DATA_START\n"
    end_marker = "\n# JSON_DATA_END"
    
    start_idx = content.find(start_marker)
    end_idx = content.find(end_marker)
    
    if start_idx == -1 or end_idx == -1:
        raise ValueError("æ— æ³•ä»txtæ–‡ä»¶ä¸­è§£ææ•°æ®")
    
    json_str = content[start_idx + len(start_marker):end_idx]
    return json.loads(json_str)

def main():
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python step5.py <step4è¾“å‡ºæ–‡ä»¶>")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = "step5Out.txt"
    
    print(f"ğŸ”„ æ­¥éª¤5: æ¦‚å¿µæ£€ç´¢")
    print(f"ğŸ“„ è¾“å…¥: {input_file}")
    print(f"ğŸ“„ è¾“å‡º: {output_file}")
    
    try:
        # è¯»å–step4çš„ç»“æœ
        step4_result = load_result_from_txt(input_file)
        
        if not step4_result.get("success"):
            print("âŒ è¾“å…¥æ–‡ä»¶æ˜¾ç¤ºstep4å¤±è´¥")
            sys.exit(1)
        
        # è¯»å–ä¹‹å‰æ­¥éª¤çš„ç»“æœ
        step_files = [
            (1, input_file.replace("step4Out.txt", "step1Out.txt")),
            (2, input_file.replace("step4Out.txt", "step2Out.txt")),
            (3, input_file.replace("step4Out.txt", "step3Out.txt"))
        ]
        
        previous_results = {}
        for step_num, file_path in step_files:
            if Path(file_path).exists():
                previous_results[f"step{step_num}"] = load_result_from_txt(file_path)
            else:
                print(f"âš ï¸ æ‰¾ä¸åˆ°step{step_num}è¾“å‡ºæ–‡ä»¶")
                previous_results[f"step{step_num}"] = {"success": True}
        
        # ä½¿ç”¨ç°æœ‰çš„å¤„ç†å™¨
        processor = StepByStepPipelineProcessor(
            input_file="dummy",
            output_dir="temp_step5"
        )
        
        # æ‰‹åŠ¨è®¾ç½®ä¹‹å‰æ­¥éª¤çš„ç»“æœ
        for step_key, result in previous_results.items():
            processor.step_results[step_key] = result
        processor.step_results["step4"] = step4_result
        
        # è°ƒç”¨ç°æœ‰çš„æ–¹æ³•
        result = processor.step5_concept_retrieval()
        
        # ä¿å­˜ç»“æœä¸ºtxt
        save_result_as_txt(result, output_file)
        
        if result.get("success"):
            print(f"âœ… æ­¥éª¤5å®Œæˆ: {output_file}")
        else:
            print(f"âŒ æ­¥éª¤5å¤±è´¥: {result.get('error')}")
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        sys.exit(1)

if __name__ == "__main__":
    main()
