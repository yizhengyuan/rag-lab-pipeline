"""
é…ç½®åŠ è½½å™¨æ¨¡å—
å…¼å®¹æ€§åŒ…è£…å™¨ï¼Œç”¨äºåŠ è½½å’Œç®¡ç†é¡¹ç›®é…ç½®
"""

import os
import yaml
import logging
from typing import Dict, Any, Optional
from pathlib import Path

logger = logging.getLogger(__name__)

class ConfigLoader:
    """é…ç½®åŠ è½½å™¨ - å…¼å®¹æ€§åŒ…è£…å™¨"""
    
    def __init__(self, config_data: Dict[str, Any] = None):
        """
        åˆå§‹åŒ–é…ç½®åŠ è½½å™¨
        
        Args:
            config_data: é…ç½®æ•°æ®å­—å…¸
        """
        self.config_data = config_data or {}
    
    @classmethod
    def load_config(cls, config_path: str = "config.yml") -> 'ConfigLoader':
        """
        ä»YAMLæ–‡ä»¶åŠ è½½é…ç½®
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            ConfigLoader: é…ç½®åŠ è½½å™¨å®ä¾‹
        """
        config_data = {}
        
        # å°è¯•ä»æ ¹ç›®å½•åŠ è½½ config.yml
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config_data = yaml.safe_load(f) or {}
                logger.info(f"âœ… æˆåŠŸä» {config_path} åŠ è½½é…ç½®")
            except Exception as e:
                logger.warning(f"âš ï¸ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        
        # å°è¯•ä» config/ ç›®å½•åŠ è½½
        elif os.path.exists("config/config.yml"):
            try:
                with open("config/config.yml", 'r', encoding='utf-8') as f:
                    config_data = yaml.safe_load(f) or {}
                logger.info("âœ… æˆåŠŸä» config/config.yml åŠ è½½é…ç½®")
            except Exception as e:
                logger.warning(f"âš ï¸ åŠ è½½ config/config.yml å¤±è´¥: {e}")
        
        else:
            logger.warning(f"âš ï¸ é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        
        # å¦‚æœä»ç„¶æ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®
        if not config_data:
            config_data = cls._get_default_config()
            logger.info("ğŸ”§ ä½¿ç”¨é»˜è®¤é…ç½®")
        else:
            # ğŸ”‘ æ–°å¢ï¼šè½¬æ¢é…ç½®æ ¼å¼ä»¥å…¼å®¹ SemanticChunker
            config_data = cls._convert_config_format(config_data)
        
        return cls(config_data)
    
    @staticmethod
    def _get_default_config() -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            # ğŸ”‘ ä¿®æ­£ï¼šä½¿ç”¨api.å‰ç¼€ä»¥åŒ¹é…SemanticChunkerçš„æœŸæœ›æ ¼å¼
            "api": {
                "openai_key": "sk-zk2884399e3bbb43b998bd31be7b517f82f67bb0e95df2a1",
                "model": "gpt-4o-mini",
                "embedding_model": "text-embedding-ada-002",
                "temperature": 0.1,
                "base_url": "https://api.zhizengzeng.com/v1/"
            },
            # ğŸ”‘ åŒæ—¶ä¿ç•™openai.å‰ç¼€ä»¥å…¼å®¹ç°æœ‰é…ç½®æ–‡ä»¶
            "openai": {
                "api_key": "sk-zk2884399e3bbb43b998bd31be7b517f82f67bb0e95df2a1",
                "model": "gpt-4o-mini",
                "embedding_model": "text-embedding-ada-002",
                "temperature": 0.1,
                "base_url": "https://api.zhizengzeng.com/v1/"
            },
            "vector_store": {
                "type": "chroma",
                "persist_directory": "./vector_db",
                "collection_name": "concept_pipeline",
                "dimension": 1536,
                "enable_embedding_cache": True,
                "embedding_cache_dir": "./embedding_cache",
                "cache_expiry_days": 30
            },
            # ğŸ”‘ ä¿®æ­£ï¼šä½¿ç”¨chunking.å‰ç¼€
            "chunking": {
                "buffer_size": 1,
                "breakpoint_percentile_threshold": 95
            },
            # ğŸ”‘ ä¿®æ­£ï¼šä½¿ç”¨concepts.å‰ç¼€
            "concepts": {
                "concepts_per_chunk": 5
            },
            "semantic_chunking": {
                "buffer_size": 1,
                "breakpoint_percentile_threshold": 95
            },
            "concept_extraction": {
                "concepts_per_chunk": 5
            },
            "retrieval": {
                "top_k": 5
            },
            "logging": {
                "level": "INFO"
            }
        }
    
    @staticmethod
    def _convert_config_format(config_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ”‘ æ–°å¢ï¼šè½¬æ¢é…ç½®æ ¼å¼ä»¥å…¼å®¹ä¸åŒçš„æ¨¡å—æœŸæœ›
        
        Args:
            config_data: åŸå§‹é…ç½®æ•°æ®
            
        Returns:
            Dict[str, Any]: è½¬æ¢åçš„é…ç½®æ•°æ®
        """
        converted = config_data.copy()
        
        # å¦‚æœå­˜åœ¨ openai é…ç½®ä½†æ²¡æœ‰ api é…ç½®ï¼Œåˆ™åˆ›å»º api é…ç½®
        if "openai" in converted and "api" not in converted:
            openai_config = converted["openai"]
            converted["api"] = {
                "openai_key": openai_config.get("api_key"),
                "model": openai_config.get("model"),
                "embedding_model": openai_config.get("embedding_model"), 
                "temperature": openai_config.get("temperature"),
                "base_url": openai_config.get("base_url")
            }
            logger.info("ğŸ”„ å·²å°† openai.* é…ç½®è½¬æ¢ä¸º api.* æ ¼å¼")
        
        # å¦‚æœå­˜åœ¨ semantic_chunking ä½†æ²¡æœ‰ chunkingï¼Œåˆ›å»º chunking é…ç½®
        if "semantic_chunking" in converted and "chunking" not in converted:
            converted["chunking"] = converted["semantic_chunking"].copy()
            logger.info("ğŸ”„ å·²å°† semantic_chunking.* é…ç½®è½¬æ¢ä¸º chunking.* æ ¼å¼")
        
        # å¦‚æœå­˜åœ¨ concept_extraction ä½†æ²¡æœ‰ conceptsï¼Œåˆ›å»º concepts é…ç½®  
        if "concept_extraction" in converted and "concepts" not in converted:
            converted["concepts"] = converted["concept_extraction"].copy()
            logger.info("ğŸ”„ å·²å°† concept_extraction.* é…ç½®è½¬æ¢ä¸º concepts.* æ ¼å¼")
        
        return converted
    
    def get(self, key_path: str, default=None):
        """
        è·å–é…ç½®å€¼ï¼Œæ”¯æŒç‚¹å·è·¯å¾„
        
        Args:
            key_path: é…ç½®è·¯å¾„ï¼Œå¦‚ 'vector_store.type' æˆ– 'openai.model'
            default: é»˜è®¤å€¼
            
        Returns:
            é…ç½®å€¼
        """
        keys = key_path.split('.')
        value = self.config_data
        
        for key in keys:
            if isinstance(value, dict) and key in value:
                value = value[key]
            else:
                return default
        
        return value
    
    def set(self, key_path: str, value: Any):
        """
        è®¾ç½®é…ç½®å€¼
        
        Args:
            key_path: é…ç½®è·¯å¾„
            value: æ–°å€¼
        """
        keys = key_path.split('.')
        config = self.config_data
        
        for key in keys[:-1]:
            if key not in config:
                config[key] = {}
            config = config[key]
        
        config[keys[-1]] = value
    
    def to_dict(self) -> Dict[str, Any]:
        """è¿”å›é…ç½®å­—å…¸"""
        return self.config_data.copy()
    
    def save_to_file(self, filepath: str):
        """ä¿å­˜é…ç½®åˆ°æ–‡ä»¶"""
        try:
            Path(filepath).parent.mkdir(parents=True, exist_ok=True)
            with open(filepath, 'w', encoding='utf-8') as f:
                yaml.dump(self.config_data, f, default_flow_style=False, allow_unicode=True)
            logger.info(f"é…ç½®å·²ä¿å­˜åˆ°: {filepath}")
        except Exception as e:
            logger.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
            raise e
    
    def validate(self) -> bool:
        """éªŒè¯é…ç½®çš„æœ‰æ•ˆæ€§"""
        try:
            # æ£€æŸ¥å¿…éœ€çš„é…ç½®é¡¹ - ä¼˜å…ˆæ£€æŸ¥api.å‰ç¼€æ ¼å¼
            required_keys = [
                "api.openai_key",
                "api.model", 
                "vector_store.type"
            ]
            
            for key in required_keys:
                if not self.get(key):
                    # å¦‚æœapi.æ ¼å¼ä¸å­˜åœ¨ï¼Œå°è¯•openai.æ ¼å¼ä½œä¸ºå¤‡é€‰
                    if key.startswith("api."):
                        fallback_key = key.replace("api.", "openai.")
                        if self.get(fallback_key):
                            logger.info(f"âœ… ä½¿ç”¨å¤‡é€‰é…ç½®æ ¼å¼: {fallback_key}")
                            continue
                    
                    logger.error(f"âŒ ç¼ºå°‘å¿…éœ€çš„é…ç½®é¡¹: {key}")
                    return False
            
            # æ£€æŸ¥å‘é‡æ•°æ®åº“ç±»å‹
            vector_type = self.get("vector_store.type")
            if vector_type not in ["simple", "chroma", "pinecone", "qdrant"]:
                logger.warning(f"âš ï¸ æœªçŸ¥çš„å‘é‡æ•°æ®åº“ç±»å‹: {vector_type}")
            
            logger.info("âœ… é…ç½®éªŒè¯é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®éªŒè¯å¤±è´¥: {e}")
            return False
    
    def update_from_dict(self, update_dict: Dict[str, Any]):
        """ä»å­—å…¸æ›´æ–°é…ç½®"""
        def merge_dict(base: Dict, update: Dict) -> Dict:
            """é€’å½’åˆå¹¶å­—å…¸"""
            result = base.copy()
            for key, value in update.items():
                if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                    result[key] = merge_dict(result[key], value)
                else:
                    result[key] = value
            return result
        
        self.config_data = merge_dict(self.config_data, update_dict)
    
    def get_section(self, section_name: str) -> Dict[str, Any]:
        """
        è·å–é…ç½®çš„æŸä¸ªéƒ¨åˆ†
        
        Args:
            section_name: éƒ¨åˆ†åç§°ï¼Œå¦‚ 'openai' æˆ– 'vector_store'
            
        Returns:
            è¯¥éƒ¨åˆ†çš„é…ç½®å­—å…¸
        """
        return self.config_data.get(section_name, {})
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        vector_type = self.get("vector_store.type", "unknown")
        model = self.get("openai.model", "unknown")
        return f"ConfigLoader(vector_store={vector_type}, model={model})"
    
    def __repr__(self) -> str:
        """è¯¦ç»†å­—ç¬¦ä¸²è¡¨ç¤º"""
        return self.__str__()

# ä¾¿åˆ©å‡½æ•°
def load_config(config_path: str = "config.yml") -> ConfigLoader:
    """
    ä¾¿åˆ©å‡½æ•°ï¼šåŠ è½½é…ç½®
    
    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        
    Returns:
        ConfigLoader: é…ç½®åŠ è½½å™¨å®ä¾‹
    """
    return ConfigLoader.load_config(config_path)

def create_default_config(filepath: str = "config.yml"):
    """
    åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
    
    Args:
        filepath: é…ç½®æ–‡ä»¶è·¯å¾„
    """
    config = ConfigLoader()
    config.save_to_file(filepath)
    logger.info(f"âœ… é»˜è®¤é…ç½®æ–‡ä»¶å·²åˆ›å»º: {filepath}")

# å…¨å±€é…ç½®å®ä¾‹
_global_config: Optional[ConfigLoader] = None

def get_global_config() -> ConfigLoader:
    """è·å–å…¨å±€é…ç½®å®ä¾‹"""
    global _global_config
    if _global_config is None:
        _global_config = load_config()
    return _global_config

def set_global_config(config: ConfigLoader):
    """è®¾ç½®å…¨å±€é…ç½®å®ä¾‹"""
    global _global_config
    _global_config = config 