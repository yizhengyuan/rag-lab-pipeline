#!/usr/bin/env python3
"""
æ­¥éª¤6: è¯æ®æå– - åŸºäºpipeline0604.py
================

ç”¨æ³•: python step6.py step5Out.txt
"""

import sys
import json
from pathlib import Path
from datetime import datetime

# å¯¼å…¥ç°æœ‰çš„å¤„ç†å™¨ç±»
sys.path.append(str(Path(__file__).parent))
from pipeline0604 import StepByStepPipelineProcessor

def save_result_as_txt(result, output_file):
    """ä¿å­˜ç»“æœä¸ºtxtæ ¼å¼"""
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("æ­¥éª¤6: è¯æ®æå– - å¤„ç†ç»“æœ\n")
        f.write("="*80 + "\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"å¤„ç†çŠ¶æ€: {'âœ… æˆåŠŸ' if result.get('success') else 'âŒ å¤±è´¥'}\n")
        
        if result.get("success"):
            stats = result.get("statistics", {})
            
            f.write(f"\nğŸ“Š è¯æ®æå–ç»Ÿè®¡:\n")
            f.write(f"- æ€»è¯æ®æ•°: {stats.get('total_evidence', 0)}\n")
            f.write(f"- æœ‰è¯æ®çš„æ¦‚å¿µæ•°: {stats.get('concepts_with_evidence', 0)}\n")
            f.write(f"- å¹³å‡æ¯æ¦‚å¿µè¯æ®æ•°: {stats.get('avg_evidence_per_concept', 0):.2f}\n")
            f.write(f"- å¹³å‡è¯æ®é•¿åº¦: {stats.get('avg_evidence_length', 0):.1f} å­—ç¬¦\n")
            f.write(f"- å¹³å‡ç›¸å…³æ€§åˆ†æ•°: {stats.get('avg_relevance_score', 0):.4f}\n")
            f.write(f"- å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f} ç§’\n")
            
            # æ˜¾ç¤ºè¯æ®ç±»å‹åˆ†å¸ƒ
            evidence_type_dist = stats.get("evidence_type_distribution", {})
            if evidence_type_dist:
                f.write(f"\nğŸ“ˆ è¯æ®ç±»å‹åˆ†å¸ƒ:\n")
                for evidence_type, count in evidence_type_dist.items():
                    f.write(f"  - {evidence_type}: {count} ä¸ª\n")
            
            # æ˜¾ç¤ºè¯æ®è¯¦æƒ…
            evidence_nodes = result.get("evidence_nodes", [])
            f.write(f"\nğŸ” è¯æ®è¯¦ç»†ä¿¡æ¯:\n")
            f.write("-" * 80 + "\n")
            
            for i, evidence in enumerate(evidence_nodes, 1):
                f.write(f"\nè¯æ® {i}:\n")
                f.write(f"  ID: {evidence.get('evidence_id', 'æœªçŸ¥')}\n")
                f.write(f"  å…³è”æ¦‚å¿µ: {evidence.get('concept_text', 'æœªçŸ¥')}\n")
                f.write(f"  è¯æ®ç±»å‹: {evidence.get('evidence_type', 'æœªçŸ¥')}\n")
                f.write(f"  ç›¸å…³æ€§åˆ†æ•°: {evidence.get('relevance_score', 0):.4f}\n")
                f.write(f"  è¯æ®é•¿åº¦: {evidence.get('evidence_length', 0)} å­—ç¬¦\n")
                f.write(f"  æ¥æºåˆ†å—: {evidence.get('source_chunks', [])}\n")
                f.write(f"  è¯æ®å†…å®¹: {evidence.get('evidence_text', '')[:200]}...\n")
                f.write("-" * 60 + "\n")
            
            # æŒ‰æ¦‚å¿µåˆ†ç»„æ˜¾ç¤ºè¯æ®
            evidence_by_concept = result.get("evidence_by_concept", {})
            f.write(f"\nğŸ“‹ æŒ‰æ¦‚å¿µåˆ†ç»„çš„è¯æ®:\n")
            f.write("-" * 80 + "\n")
            
            for concept_id, evidences in evidence_by_concept.items():
                if evidences:
                    concept_text = evidences[0].get('concept_text', 'æœªçŸ¥æ¦‚å¿µ')
                    f.write(f"\næ¦‚å¿µ: {concept_text}\n")
                    f.write(f"  æ¦‚å¿µID: {concept_id}\n")
                    f.write(f"  è¯æ®æ•°é‡: {len(evidences)}\n")
                    
                    for j, evidence in enumerate(evidences, 1):
                        f.write(f"  è¯æ® {j}: ç›¸å…³æ€§ {evidence.get('relevance_score', 0):.3f} - {evidence.get('evidence_text', '')[:100]}...\n")
                    
                    f.write("-" * 40 + "\n")
            
            # æ˜¾ç¤ºè¯æ®è´¨é‡åˆ†æ
            f.write(f"\nğŸ“ˆ è¯æ®è´¨é‡åˆ†æ:\n")
            f.write("-" * 60 + "\n")
            
            if evidence_nodes:
                # ç›¸å…³æ€§åˆ†æ•°åˆ†æ
                relevance_scores = [e.get('relevance_score', 0) for e in evidence_nodes]
                high_quality = [e for e in evidence_nodes if e.get('relevance_score', 0) >= 0.8]
                medium_quality = [e for e in evidence_nodes if 0.5 <= e.get('relevance_score', 0) < 0.8]
                low_quality = [e for e in evidence_nodes if e.get('relevance_score', 0) < 0.5]
                
                f.write(f"ç›¸å…³æ€§åˆ†æ•°åˆ†å¸ƒ:\n")
                f.write(f"  - é«˜è´¨é‡ (â‰¥0.8): {len(high_quality)} ä¸ª\n")
                f.write(f"  - ä¸­ç­‰è´¨é‡ (0.5-0.8): {len(medium_quality)} ä¸ª\n")
                f.write(f"  - ä½è´¨é‡ (<0.5): {len(low_quality)} ä¸ª\n")
                
                if relevance_scores:
                    max_score = max(relevance_scores)
                    min_score = min(relevance_scores)
                    f.write(f"  - æœ€é«˜åˆ†æ•°: {max_score:.4f}\n")
                    f.write(f"  - æœ€ä½åˆ†æ•°: {min_score:.4f}\n")
                
                # è¯æ®é•¿åº¦åˆ†æ
                evidence_lengths = [e.get('evidence_length', 0) for e in evidence_nodes]
                if evidence_lengths:
                    avg_length = sum(evidence_lengths) / len(evidence_lengths)
                    max_length = max(evidence_lengths)
                    min_length = min(evidence_lengths)
                    f.write(f"\nè¯æ®é•¿åº¦åˆ†æ:\n")
                    f.write(f"  - å¹³å‡é•¿åº¦: {avg_length:.1f} å­—ç¬¦\n")
                    f.write(f"  - æœ€é•¿è¯æ®: {max_length} å­—ç¬¦\n")
                    f.write(f"  - æœ€çŸ­è¯æ®: {min_length} å­—ç¬¦\n")
                
                # æ˜¾ç¤ºé«˜è´¨é‡è¯æ®ç¤ºä¾‹
                if high_quality:
                    f.write(f"\nğŸŒŸ é«˜è´¨é‡è¯æ®ç¤ºä¾‹ (ç›¸å…³æ€§ â‰¥ 0.8):\n")
                    f.write("-" * 40 + "\n")
                    for i, evidence in enumerate(high_quality[:3], 1):
                        f.write(f"{i}. æ¦‚å¿µ: {evidence.get('concept_text', 'æœªçŸ¥')[:30]}...\n")
                        f.write(f"   ç›¸å…³æ€§: {evidence.get('relevance_score', 0):.4f}\n")
                        f.write(f"   å†…å®¹: {evidence.get('evidence_text', '')[:150]}...\n\n")
            
        else:
            f.write(f"\nâŒ é”™è¯¯ä¿¡æ¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}\n")
        
        # åœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ æœºå™¨å¯è¯»çš„æ•°æ®
        f.write(f"\n" + "="*80 + "\n")
        f.write("# æœºå™¨å¯è¯»æ•°æ® (è¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹)\n")
        f.write("# JSON_DATA_START\n")
        f.write(json.dumps(result, ensure_ascii=False, indent=2))
        f.write("\n# JSON_DATA_END\n")

def load_result_from_txt(input_file):
    """ä»txtæ–‡ä»¶ä¸­åŠ è½½ç»“æœæ•°æ®"""
    with open(input_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    start_marker = "# JSON_DATA_START\n"
    end_marker = "\n# JSON_DATA_END"
    
    start_idx = content.find(start_marker)
    end_idx = content.find(end_marker)
    
    if start_idx == -1 or end_idx == -1:
        raise ValueError("æ— æ³•ä»txtæ–‡ä»¶ä¸­è§£ææ•°æ®")
    
    json_str = content[start_idx + len(start_marker):end_idx]
    return json.loads(json_str)

def main():
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python step6.py <step5è¾“å‡ºæ–‡ä»¶>")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = "step6Out.txt"
    
    print(f"ğŸ”„ æ­¥éª¤6: è¯æ®æå–")
    print(f"ğŸ“„ è¾“å…¥: {input_file}")
    print(f"ğŸ“„ è¾“å‡º: {output_file}")
    
    try:
        # è¯»å–step5çš„ç»“æœ
        step5_result = load_result_from_txt(input_file)
        
        if not step5_result.get("success"):
            print("âŒ è¾“å…¥æ–‡ä»¶æ˜¾ç¤ºstep5å¤±è´¥")
            sys.exit(1)
        
        # è¯»å–ä¹‹å‰æ­¥éª¤çš„ç»“æœ
        step_files = [
            (1, input_file.replace("step5Out.txt", "step1Out.txt")),
            (2, input_file.replace("step5Out.txt", "step2Out.txt")),
            (3, input_file.replace("step5Out.txt", "step3Out.txt")),
            (4, input_file.replace("step5Out.txt", "step4Out.txt"))
        ]
        
        previous_results = {}
        for step_num, file_path in step_files:
            if Path(file_path).exists():
                try:
                    previous_results[f"step{step_num}"] = load_result_from_txt(file_path)
                    print(f"âœ… æˆåŠŸè¯»å– step{step_num} ç»“æœ")
                except Exception as e:
                    print(f"âš ï¸ è¯»å–step{step_num}æ–‡ä»¶å¤±è´¥: {e}")
                    previous_results[f"step{step_num}"] = {"success": True}
            else:
                print(f"âš ï¸ æ‰¾ä¸åˆ°step{step_num}è¾“å‡ºæ–‡ä»¶: {file_path}")
                previous_results[f"step{step_num}"] = {"success": True}
        
        # ä½¿ç”¨ç°æœ‰çš„å¤„ç†å™¨
        processor = StepByStepPipelineProcessor(
            input_file="dummy",
            output_dir="temp_step6"
        )
        
        # æ‰‹åŠ¨è®¾ç½®ä¹‹å‰æ­¥éª¤çš„ç»“æœ
        for step_key, result in previous_results.items():
            processor.step_results[step_key] = result
        processor.step_results["step5"] = step5_result
        
        print("ğŸ”§ å¼€å§‹æ‰§è¡Œè¯æ®æå–...")
        
        # è°ƒç”¨ç°æœ‰çš„æ–¹æ³•
        result = processor.step6_evidence_extraction()
        
        # ä¿å­˜ç»“æœä¸ºtxt
        save_result_as_txt(result, output_file)
        
        if result.get("success"):
            print(f"âœ… æ­¥éª¤6å®Œæˆ: {output_file}")
            
            # æ˜¾ç¤ºç®€è¦ç»Ÿè®¡
            stats = result.get("statistics", {})
            print(f"ğŸ“Š è¯æ®æå–ç»“æœ:")
            print(f"   - æ€»è¯æ®æ•°: {stats.get('total_evidence', 0)}")
            print(f"   - æœ‰è¯æ®çš„æ¦‚å¿µæ•°: {stats.get('concepts_with_evidence', 0)}")
            print(f"   - å¹³å‡ç›¸å…³æ€§: {stats.get('avg_relevance_score', 0):.4f}")
            print(f"   - å¤„ç†æ—¶é—´: {result.get('processing_time', 0):.2f} ç§’")
            
        else:
            print(f"âŒ æ­¥éª¤6å¤±è´¥: {result.get('error')}")
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        
        # ä¿å­˜é”™è¯¯ä¿¡æ¯åˆ°è¾“å‡ºæ–‡ä»¶
        error_result = {
            "step": 6,
            "step_name": "è¯æ®æå–",
            "success": False,
            "error": str(e),
            "processing_time": 0.0,
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            save_result_as_txt(error_result, output_file)
            print(f"ğŸ“„ é”™è¯¯ä¿¡æ¯å·²ä¿å­˜åˆ°: {output_file}")
        except:
            pass
        
        sys.exit(1)

if __name__ == "__main__":
    main()
