"""
è¯æ®æå–æ¨¡å—
"""

import logging
import numpy as np
from typing import List, Dict
from llama_index.core import VectorStoreIndex
from llama_index.core.schema import NodeWithScore
from llama_index.core.response_synthesizers import ResponseMode
from .nodes import ConceptNode, EvidenceNode

logger = logging.getLogger(__name__)

class EvidenceExtractor:
    """è¯æ®æå–å™¨ - ä½¿ç”¨ LlamaIndex çš„æŸ¥è¯¢å¼•æ“"""
    
    def __init__(self, config):
        """
        åˆå§‹åŒ–è¯æ®æå–å™¨
        
        Args:
            config: é…ç½®å¯¹è±¡
        """
        self.config = config
        self.min_length = config.get("evidence.min_length", 20)
        self.max_length = config.get("evidence.max_length", 200)
        self.evidence_nodes: List[EvidenceNode] = []
    
    def extract_evidence_for_concepts(self, 
                                    concept_nodes: List[ConceptNode],
                                    concept_to_chunks: Dict[str, List[NodeWithScore]]) -> List[EvidenceNode]:
        """
        ä¸ºæ¦‚å¿µæå–è¯æ®
        
        Args:
            concept_nodes: æ¦‚å¿µèŠ‚ç‚¹åˆ—è¡¨
            concept_to_chunks: æ¦‚å¿µåˆ°chunksçš„æ˜ å°„
            
        Returns:
            List[EvidenceNode]: è¯æ®èŠ‚ç‚¹åˆ—è¡¨
        """
        logger.info("å¼€å§‹è¯æ®æå–")
        
        self.evidence_nodes = []
        
        for concept_node in concept_nodes:
            concept_id = concept_node.node_id
            chunks = concept_to_chunks.get(concept_id, [])
            
            if not chunks:
                logger.debug(f"æ¦‚å¿µ '{concept_node.text}' æ²¡æœ‰ç›¸å…³chunksï¼Œè·³è¿‡è¯æ®æå–")
                continue
                
            logger.info(f"æ­£åœ¨ä¸ºæ¦‚å¿µ '{concept_node.text}' æå–è¯æ®")
            
            try:
                evidence = self._extract_evidence_for_single_concept(concept_node, chunks)
                if evidence:
                    self.evidence_nodes.append(evidence)
            except Exception as e:
                logger.warning(f"ä¸ºæ¦‚å¿µ '{concept_node.text}' æå–è¯æ®æ—¶å‡ºé”™: {e}")
                continue
        
        logger.info(f"å®Œæˆè¯æ®æå–: æå–äº† {len(self.evidence_nodes)} ä¸ªè¯æ®")
        return self.evidence_nodes
    
    def _extract_evidence_for_single_concept(self, 
                                           concept_node: ConceptNode, 
                                           chunks: List[NodeWithScore]) -> EvidenceNode:
        """
        ä¸ºå•ä¸ªæ¦‚å¿µæå–è¯æ®
        
        Args:
            concept_node: æ¦‚å¿µèŠ‚ç‚¹
            chunks: ç›¸å…³çš„æ–‡æ¡£å—
            
        Returns:
            EvidenceNode: è¯æ®èŠ‚ç‚¹ï¼Œå¦‚æœæå–å¤±è´¥åˆ™è¿”å›None
        """
        logger.info(f"æ­£åœ¨ä¸ºæ¦‚å¿µ '{concept_node.text}' æå–è¯æ®")
        if not chunks:
            logger.debug(f"æ¦‚å¿µ '{concept_node.text}' æ²¡æœ‰ç›¸å…³chunksï¼Œè·³è¿‡è¯æ®æå–")
            return None
        
        # åˆ›å»ºä¸´æ—¶ç´¢å¼•ç”¨äºè¯æ®æå–
        temp_nodes = [chunk.node for chunk in chunks]
        temp_index = VectorStoreIndex(temp_nodes)
        
        # ä½¿ç”¨ LlamaIndex çš„æŸ¥è¯¢å¼•æ“
        query_engine = temp_index.as_query_engine(
            response_mode=ResponseMode.COMPACT,
            similarity_top_k=3
        )
        
        # æ„å»ºè¯æ®æå–æŸ¥è¯¢
        evidence_query = self._build_evidence_query(concept_node.text)
        
        try:
            response = query_engine.query(evidence_query)
            evidence_text = str(response).strip()
            
            # éªŒè¯è¯æ®è´¨é‡
            if self._validate_evidence_quality(evidence_text):
                # è®¡ç®—ç›¸å…³æ€§åˆ†æ•°
                relevance_score = np.mean([chunk.score for chunk in chunks]) if chunks else 0.0
                
                evidence_node = EvidenceNode(
                    evidence_text=evidence_text,
                    concept_id=concept_node.node_id,
                    relevance_score=float(relevance_score),
                    id_=f"evidence_{len(self.evidence_nodes)}"
                )
                evidence_node.metadata.update({
                    "concept_text": concept_node.text,
                    "source_chunks": [chunk.node.node_id for chunk in chunks],
                    "extraction_method": "llamaindex_query_engine",
                    "evidence_length": len(evidence_text)
                })
                
                return evidence_node
            else:
                logger.debug(f"è¯æ®è´¨é‡éªŒè¯å¤±è´¥: {evidence_text[:50]}...")
                return None
                
        except Exception as e:
            logger.warning(f"è¯æ®æå–å¤±è´¥: {e}")
            return None
    
    def _build_evidence_query(self, concept: str) -> str:
        """
        æ„å»ºè¯æ®æå–æŸ¥è¯¢
        
        Args:
            concept: æ¦‚å¿µæ–‡æœ¬
            
        Returns:
            str: æŸ¥è¯¢å­—ç¬¦ä¸²
        """
        return f"""
        è¯·ä»ç»™å®šçš„æ–‡æœ¬ä¸­æå–ä¸æ¦‚å¿µ"{concept}"æœ€ç›¸å…³çš„è¯æ®ç‰‡æ®µã€‚
        è¦æ±‚ï¼š
        1. æå–çš„è¯æ®åº”è¯¥ç›´æ¥æ”¯æŒæˆ–è§£é‡Šè¯¥æ¦‚å¿µ
        2. å»é™¤æ— å…³ä¿¡æ¯å’Œå™ªå£°
        3. ä¿æŒè¯æ®çš„å®Œæ•´æ€§å’Œå‡†ç¡®æ€§
        4. è¯æ®é•¿åº¦æ§åˆ¶åœ¨{self.min_length}-{self.max_length}å­—
        è¯·ç›´æ¥è¿”å›æå–çš„è¯æ®æ–‡æœ¬ï¼Œä¸éœ€è¦é¢å¤–è¯´æ˜ã€‚
        """
    
    def _validate_evidence_quality(self, evidence_text: str) -> bool:
        """
        éªŒè¯è¯æ®è´¨é‡
        
        Args:
            evidence_text: è¯æ®æ–‡æœ¬
            
        Returns:
            bool: æ˜¯å¦é€šè¿‡è´¨é‡éªŒè¯
        """
        if not evidence_text:
            logger.debug(f"è¯æ®ä¸ºç©º")
            return False
        
        # æ£€æŸ¥é•¿åº¦
        if len(evidence_text) < self.min_length:
            logger.debug(f"è¯æ®å¤ªçŸ­: {len(evidence_text)} < {self.min_length}")
            return False
        
        if len(evidence_text) > self.max_length * 3:  # æ”¾å®½é•¿åº¦é™åˆ¶
            logger.debug(f"è¯æ®å¤ªé•¿: {len(evidence_text)} > {self.max_length * 3}")
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„å†…å®¹
        meaningless_phrases = ["", "æ— ", "æ²¡æœ‰", "ä¸çŸ¥é“", "æ— æ³•ç¡®å®š", "æ— ç›¸å…³å†…å®¹"]
        if evidence_text.strip() in meaningless_phrases:
            logger.debug(f"è¯æ®æ— æ„ä¹‰: {evidence_text}")
            return False
        
        # ğŸ”§ ä¿®å¤ï¼šåªæ£€æŸ¥æ˜ç¡®çš„APIé”™è¯¯å“åº”ï¼Œä¸æ‹’ç»æ³•å¾‹æœ¯è¯­
        api_error_indicators = ["æŠ±æ­‰ï¼Œæˆ‘æ— æ³•", "APIè°ƒç”¨å¤±è´¥", "è¯·æ±‚è¶…æ—¶", "æœåŠ¡ä¸å¯ç”¨"]
        if any(indicator in evidence_text for indicator in api_error_indicators):
            logger.debug(f"æ£€æµ‹åˆ°APIé”™è¯¯å“åº”: {evidence_text[:50]}...")
            return False
        
        # ğŸ†• æ·»åŠ ï¼šè¾“å‡ºé€šè¿‡éªŒè¯çš„è¯æ®ç”¨äºè°ƒè¯•
        logger.debug(f"è¯æ®é€šè¿‡éªŒè¯: {evidence_text[:100]}...")
        return True
    
    def get_evidence_statistics(self) -> Dict[str, any]:
        """
        è·å–è¯æ®æå–ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            Dict[str, any]: ç»Ÿè®¡ä¿¡æ¯
        """
        if not self.evidence_nodes:
            return {"total_evidence": 0}
        
        evidence_lengths = [len(node.text) for node in self.evidence_nodes]
        relevance_scores = [node.relevance_score for node in self.evidence_nodes]
        
        return {
            "total_evidence": len(self.evidence_nodes),
            "avg_evidence_length": np.mean(evidence_lengths),
            "min_evidence_length": min(evidence_lengths),
            "max_evidence_length": max(evidence_lengths),
            "avg_relevance_score": np.mean(relevance_scores),
            "min_relevance_score": min(relevance_scores),
            "max_relevance_score": max(relevance_scores)
        } 