================================================================================
步骤6_证据提取 - 详细报告
================================================================================
生成时间: 2025-06-04 19:31:19
处理文件: attention is all you need.pdf
================================================================================


证据提取统计:
- 输入概念数: 6
- 提取的证据数: 5
- 处理时间: 59.31 秒

证据提取详情:
------------------------------------------------------------

证据 1:
- 证据ID: evidence_0
- 关联概念: 认知与行为的探索与发展
- 相关性分数: 3.750
- 证据长度: 29 字符
- 证据内容: 抱歉，无法提供与“认知与行为的探索与发展”相关的证据片段。...
----------------------------------------

证据 2:
- 证据ID: evidence_1
- 关联概念: 优先选择的会议预印本
- 相关性分数: 2.700
- 证据长度: 115 字符
- 证据内容: 在WMT 2014英语到德语翻译任务中，大型变换器模型（表2中的Transformer (big)）比之前报告的最佳模型（包括集成模型）提高了超过2.0 BLEU，确立了28.4的新状态下BLEU分数...
----------------------------------------

证据 3:
- 证据ID: evidence_2
- 关联概念: 文化与国际交流
- 相关性分数: 3.000
- 证据长度: 25 字符
- 证据内容: 抱歉，无法提供与“文化与国际交流”相关的证据片段。...
----------------------------------------

证据 4:
- 证据ID: evidence_3
- 关联概念: 研究成果的可用性与优化状态
- 相关性分数: 3.250
- 证据长度: 137 字符
- 证据内容: 我们展示了Transformer在英语成分解析任务上的良好泛化能力。尽管缺乏特定任务的调优，我们的模型表现出色，超越了所有先前报告的模型，除了递归神经网络语法模型。与递归神经网络序列到序列模型相比，T...
----------------------------------------

证据 5:
- 证据ID: evidence_4
- 关联概念: 替代或附加的方式
- 相关性分数: 3.500
- 证据长度: 590 字符
- 证据内容: Attention Is All You Need
The dominant sequence transduction models are based on complex recurrent o...
----------------------------------------
