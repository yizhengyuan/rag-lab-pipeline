# ConceptBasedPipeline ä¸»é…ç½®æ–‡ä»¶
# =====================================

# OpenAI è®¾ç½®
openai:
  api_key: "sk-zk2884399e3bbb43b998bd31be7b517f82f67bb0e95df2a1"
  model: "gpt-4o-mini"
  embedding_model: "text-embedding-ada-002"
  temperature: 0.1
  base_url: "https://api.zhizengzeng.com/v1/"

# å‘é‡æ•°æ®åº“è®¾ç½®
vector_store:
  # å‘é‡æ•°æ®åº“ç±»å‹: chroma | simple | faiss
  type: "chroma"
  # æœ¬åœ°å­˜å‚¨è·¯å¾„
  persist_directory: "./vector_db"
  # é›†åˆåç§°
  collection_name: "concept_pipeline"
  # å‘é‡ç»´åº¦ (OpenAI text-embedding-ada-002 æ˜¯ 1536)
  dimension: 1536
  # æ˜¯å¦å¯ç”¨embeddingç¼“å­˜
  enable_embedding_cache: true
  # embeddingç¼“å­˜ç›®å½•
  embedding_cache_dir: "./embedding_cache"
  # ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆå¤©ï¼‰
  cache_expiry_days: 30

# é—®ç­”ç”Ÿæˆè®¾ç½®
qa_generation:
  questions_per_type:
    remember: 2
    understand: 2
    apply: 1
    analyze: 1
    evaluate: 1
    create: 1

# è¯­ä¹‰åˆ†å—è®¾ç½®
semantic_chunking:
  buffer_size: 1
  breakpoint_percentile_threshold: 95

# æ¦‚å¿µæå–è®¾ç½®
concept_extraction:
  concepts_per_chunk: 5

# æ¦‚å¿µåˆå¹¶è®¾ç½®
concept_merging:
  similarity_threshold: 0.7
  max_document_concepts: 10

# æ£€ç´¢è®¾ç½®
retrieval:
  top_k: 5
  similarity_cutoff: 0.2  # é™ä½ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œæé«˜æ£€ç´¢è¦†ç›–ç‡
  max_retrievals_per_concept: 10  # å¯é€‰ï¼šå¢åŠ æ¯ä¸ªæ¦‚å¿µçš„æœ€å¤§æ£€ç´¢æ•°

# Evidence æå–è®¾ç½®  
evidence_extraction:
  min_length: 20
  max_length: 400  # å¢åŠ æœ€å¤§é•¿åº¦ï¼Œå…è®¸æ›´é•¿çš„è¯æ®
  min_relevance_threshold: 0.2  # è®¾ç½®æœ€å°ç›¸å…³æ€§é˜ˆå€¼

# è¾“å‡ºè®¾ç½®
output:
  directory: "integrated_output"
  save_intermediate_results: true

# æ—¥å¿—è®¾ç½®
logging:
  level: "INFO"

# æç¤ºè¯æ¨¡æ¿ - é€šç”¨ç‰ˆæœ¬ï¼ˆé€‚åº”æ‰€æœ‰é¢†åŸŸï¼‰
# æç¤ºè¯æ¨¡æ¿ - é€šç”¨ç‰ˆæœ¬ï¼ˆé€‚åº”æ‰€æœ‰é¢†åŸŸï¼‰
prompts:
  concept_extraction: |
    You are an expert in extracting key concepts from academic and professional documents across various domains.
    
    Task: Analyze the following text and extract {num_concepts} important concepts that capture the main ideas and themes.
    
    Text:
    {text}
    
    EXTRACTION GUIDELINES:
    
    âœ… GOOD concepts (2-6 words each):
    - Domain-specific terminology: "quantum mechanics", "criminal liability", "cellular respiration", "market volatility"
    - Key processes: "photosynthesis process", "democratic governance", "supply chain management", "clinical diagnosis"
    - Important entities: "Supreme Court", "mitochondrial DNA", "financial derivatives", "Renaissance art"
    - Methods and approaches: "systematic review", "case study analysis", "experimental design", "policy implementation"
    - Core principles: "due process", "conservation of energy", "market equilibrium", "narrative structure"
    
    âŒ AVOID these (low-quality concepts):
    - Single generic words: "method", "system", "process", "study", "analysis"
    - Common adjectives: "good", "bad", "new", "old", "important", "significant"
    - Vague terms: "things", "aspects", "factors", "elements", "issues"
    - Document meta-references: "paper", "article", "research", "study", "work"
    - Too general terms: "information", "data", "knowledge", "content"
    
    SPECIFIC REQUIREMENTS:
    1. Extract exactly {num_concepts} concepts
    2. Each concept must be 2-6 words long
    3. Focus on domain-specific terminology and key ideas from the text
    4. Concepts should be specific enough to be meaningful within the document's context
    5. Prefer compound terms that capture precise meaning over single words
    
    Return the concepts in JSON format:
    {{"concepts": ["concept 1", "concept 2", "concept 3"]}}

  concept_mapping: |
    You are an expert educator specializing in creating detailed concept maps from academic texts. Given the following excerpt from a longer document, extract the main ideas, detailed concepts, and supporting details that are critical to understanding the material.
    
    Focus on identifying:
    - Key concepts or terms introduced in the text
    - Definitions or explanations of these concepts
    - Relationships between concepts
    - Any examples or applications mentioned
    
    Context:
    {context}
    
    CONCEPT MAP EXTRACTION GUIDELINES:
    
    âœ… IDENTIFY AND STRUCTURE:
    1. **Main Topics**: Overarching themes or subject areas
    2. **Key Concepts**: Important terms, principles, or ideas
    3. **Definitions**: Clear explanations of concepts
    4. **Relationships**: How concepts connect to each other
    5. **Examples**: Specific instances or applications
    6. **Supporting Details**: Evidence, data, or elaborations
    
    âœ… ORGANIZATION PRINCIPLES:
    - Group related concepts under common topics
    - Show hierarchical relationships (general â†’ specific)
    - Indicate cause-and-effect connections
    - Highlight compare/contrast relationships
    - Note process sequences or temporal relationships
    
    âœ… FORMATTING REQUIREMENTS:
    - Use clear, bullet-point summaries
    - Organize by topic/theme
    - Include concept relationships explicitly
    - Provide concise but complete information
    
    Return the structured concept map in JSON format:
    {{
      "main_topics": [
        {{
          "topic": "Topic Name",
          "key_concepts": [
            {{
              "concept": "Concept Name",
              "definition": "Clear definition or explanation",
              "relationships": ["connects to concept X", "causes concept Y"],
              "examples": ["example 1", "example 2"],
              "supporting_details": ["detail 1", "detail 2"]
            }}
          ]
        }}
      ],
      "cross_topic_relationships": [
        {{
          "concept_1": "Concept from Topic A",
          "concept_2": "Concept from Topic B", 
          "relationship_type": "causes/enables/supports/contrasts_with",
          "description": "Brief explanation of the relationship"
        }}
      ]
    }}

  concept_merging: |
    You are an expert in consolidating related concepts from academic and professional documents.
    
    Task: Merge the following similar concepts into a single, more comprehensive concept phrase.
    
    Related concepts to merge:
    {concepts}
    
    MERGING GUIDELINES:
    - Create a unified concept that captures the essence of all input concepts
    - Use appropriate domain terminology (2-6 words)
    - The merged concept should be specific enough to be meaningful
    - Prefer established terms from the relevant field when possible
    
    Examples:
    - ["heart disease", "cardiac conditions", "cardiovascular problems"] â†’ "cardiovascular disease"
    - ["legal precedent", "case law", "judicial decisions"] â†’ "legal precedent"
    - ["market analysis", "economic evaluation", "financial assessment"] â†’ "market analysis"
    - ["historical context", "historical background", "historical setting"] â†’ "historical context"
    
    Return only the merged concept phrase (no explanation needed):

  evidence_extraction: |
    You are a research analyst specializing in extracting supporting evidence from academic and professional documents.
    
    Task: Extract evidence text that directly supports the given concept from the provided source text.
    
    Target concept: {concept}
    
    Source text:
    {text}
    
    EVIDENCE EXTRACTION REQUIREMENTS:
    1. Find 1-3 sentences that directly relate to or explain the concept
    2. Evidence must be accurate and specific to the concept
    3. Preserve original terminology and precise wording
    4. Select complete sentences that provide clear explanations or details
    5. Evidence should help someone understand what the concept means or how it applies
    
    QUALITY CRITERIA:
    âœ… Good evidence contains:
    - Clear definitions or explanations
    - Specific examples or case studies
    - Statistical data or measurements
    - Cause-and-effect relationships
    - Comparative information
    - Implementation details or procedures
    
    âŒ Avoid evidence that is:
    - Too general or vague
    - Incomplete sentences
    - References without context
    - Unrelated background information
    - Purely speculative statements
    
    Return the evidence in JSON format:
    {{"evidence": ["evidence sentence 1", "evidence sentence 2"]}}

  qa_generation_system: |
    You are an expert educator specializing in creating high-quality questions across various academic and professional domains.
    
    Your questions should help learners understand and apply knowledge at different cognitive levels following Bloom's Taxonomy, regardless of the subject matter.

  qa_generation_user: |
    Based on the following evidence text, generate {questions_per_type} high-quality questions for each cognitive level.
    
    Evidence text:
    {evidence_text}
    
    Generate questions following these specifications:
    
    REMEMBER level (factual recall):
    - What specific terms, names, dates, or facts are mentioned?
    - What are the key definitions or factual information presented?
    
    UNDERSTAND level (comprehension):
    - How do the concepts work or function?
    - What are the relationships between different elements?
    - What is the meaning or significance of the information?
    
    APPLY level (application):
    - How would you use this knowledge in a practical situation?
    - In what scenarios would this information be most relevant?
    - How could this be implemented or applied?
    
    ANALYZE level (analysis):
    - What are the components, causes, or consequences discussed?
    - How do different elements compare or contrast?
    - What patterns or relationships can be identified?
    
    EVALUATE level (evaluation):
    - What criteria would you use to assess or judge this information?
    - What are the strengths, weaknesses, or limitations?
    - How valid or reliable is this information?
    
    CREATE level (synthesis):
    - How could you combine this with other knowledge to create something new?
    - What alternative approaches or solutions could you propose?
    - How might you adapt or modify this for different contexts?
    
    ANSWER REQUIREMENTS:
    - Answers should be accurate and detailed based on the evidence
    - Include specific examples when possible
    - Reference the evidence text appropriately
    - Use appropriate domain terminology
    
    Return the questions and answers in JSON format:
    {{
      "remember": [
        {{"question": "...", "answer": "...", "difficulty": "easy"}},
        {{"question": "...", "answer": "...", "difficulty": "easy"}}
      ],
      "understand": [
        {{"question": "...", "answer": "...", "difficulty": "medium"}},
        {{"question": "...", "answer": "...", "difficulty": "medium"}}
      ],
      "apply": [
        {{"question": "...", "answer": "...", "difficulty": "medium"}}
      ],
      "analyze": [
        {{"question": "...", "answer": "...", "difficulty": "hard"}}
      ],
      "evaluate": [
        {{"question": "...", "answer": "...", "difficulty": "hard"}}
      ],
      "create": [
        {{"question": "...", "answer": "...", "difficulty": "hard"}}
      ]
    }}

# é«˜çº§è®¾ç½®ï¼ˆå¯é€‰ï¼‰
advanced:
  # ğŸ”§ ç½‘ç»œè¿æ¥ä¼˜åŒ–é…ç½®ï¼ˆæ›´ä¿å®ˆçš„è®¾ç½®ï¼‰
  max_concurrent_requests: 1       # æ”¹ä¸º1ï¼Œé¿å…å¹¶å‘å†²çª
  request_timeout: 120             # å¢åŠ åˆ°120ç§’
  max_retries: 8                   # å¢åŠ é‡è¯•æ¬¡æ•°
  retry_delay: 5                   # å¢åŠ é‡è¯•é—´éš”
  backoff_factor: 3                # å¢åŠ é€€é¿å› å­
  
  # ğŸ›¡ï¸ SSLå’Œè¿æ¥é…ç½®
  verify_ssl: false                # å¦‚æœSSLæœ‰é—®é¢˜ï¼Œå¯æš‚æ—¶ç¦ç”¨éªŒè¯
  connection_pool_size: 5          # å‡å°è¿æ¥æ± 
  connection_pool_maxsize: 10      # å‡å°æœ€å¤§è¿æ¥æ•°
  
  # ğŸ“¡ APIé…ç½®ä¼˜åŒ–
  chunk_size: 5                    # å‡å°æ‰¹æ¬¡å¤§å°
  embedding_batch_delay: 3         # å¢åŠ æ‰¹æ¬¡é—´å»¶è¿Ÿ
  
  # ç¼“å­˜è®¾ç½®
  enable_cache: true
  cache_directory: ".cache"
  
  # å®éªŒæ€§åŠŸèƒ½
  experimental:
    enable_concept_hierarchy: false
    use_multi_stage_evidence: false

# ğŸ†• Chunkingé…ç½® - æ·»åŠ tokené™åˆ¶
chunking:
  # è¯­ä¹‰åˆ†å—å‚æ•°
  buffer_size: 1
  breakpoint_percentile_threshold: 95
  
  # ğŸ”‘ Tokené™åˆ¶ï¼ˆé˜²æ­¢APIé”™è¯¯ï¼‰
  max_tokens_per_chunk: 6000  # embeddingæ¨¡å‹tokené™åˆ¶ï¼Œä¿ç•™ä½™é‡
  max_char_per_chunk: 24000   # å­—ç¬¦æ•°é™åˆ¶ï¼ˆçº¦4:1æ¯”ä¾‹ï¼‰
  
  # åˆ†å‰²ç­–ç•¥
  enable_fallback_splitting: true
  fallback_chunk_overlap: 200
  min_chunk_length: 10        # æœ€å°chunké•¿åº¦ï¼ˆå­—ç¬¦ï¼‰
  
  # å®‰å…¨æ£€æŸ¥
  enable_token_validation: true
  skip_oversized_chunks: false  # false=åˆ†å‰²ï¼Œtrue=è·³è¿‡ 