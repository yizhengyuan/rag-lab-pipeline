"""
Pipeline è°ƒè¯•å·¥å…· - å±•ç¤ºæ‰€æœ‰ä¸­é—´æ­¥éª¤çš„è¯¦ç»†ç»“æœ
=======================================================

åŠŸèƒ½ï¼š
1. è¯¦ç»†è®°å½•æ¯ä¸ªæ­¥éª¤çš„è¾“å…¥è¾“å‡º
2. ä¿å­˜ä¸­é—´ç»“æœåˆ°å¯è¯»æ ¼å¼
3. ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
4. æä¾›è´¨é‡è¯„ä¼°æŒ‡æ ‡
"""

import os
import json
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import traceback
from pathlib import Path

# å¯¼å…¥ä¸»è¦çš„ Pipeline ç±»
from integrated_pipeline_new import ModularIntegratedPipeline
from llama_index.core import Document
from debug_visualizer import PipelineVisualizer

logger = logging.getLogger(__name__)

class PipelineDebugger:
    """Pipeline è°ƒè¯•å™¨ - è¯¦ç»†è®°å½•æ¯ä¸ªæ­¥éª¤"""
    
    def __init__(self, 
                 config_path: str = "config/config.yml",
                 debug_output_dir: str = "./debug_output"):
        """
        åˆå§‹åŒ–è°ƒè¯•å™¨
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            debug_output_dir: è°ƒè¯•è¾“å‡ºç›®å½•
        """
        self.debug_output_dir = debug_output_dir
        self.config_path = config_path
        
        # åˆ›å»ºè°ƒè¯•è¾“å‡ºç›®å½•
        os.makedirs(debug_output_dir, exist_ok=True)
        
        # åˆå§‹åŒ–ä¸» Pipeline
        self.pipeline = ModularIntegratedPipeline(
            config_path=config_path,
            output_dir=debug_output_dir
        )
        
        # åˆå§‹åŒ–å¯è§†åŒ–å™¨
        self.visualizer = PipelineVisualizer(debug_output_dir)
        
        # è°ƒè¯•ä¿¡æ¯å­˜å‚¨
        self.debug_info = {
            "steps": [],
            "timing": {},
            "quality_metrics": {},
            "errors": []
        }
        
        logger.info(f"ğŸ” Pipeline è°ƒè¯•å™¨å·²åˆå§‹åŒ–")
        logger.info(f"ğŸ“ è°ƒè¯•è¾“å‡ºç›®å½•: {debug_output_dir}")
    
    def debug_full_pipeline(self, file_path: str) -> Dict[str, Any]:
        """
        è°ƒè¯•å®Œæ•´çš„ Pipeline æµç¨‹
        
        Args:
            file_path: è¾“å…¥æ–‡ä»¶è·¯å¾„
            
        Returns:
            åŒ…å«æ‰€æœ‰è°ƒè¯•ä¿¡æ¯çš„å­—å…¸
        """
        start_time = datetime.now()
        file_name = os.path.basename(file_path)
        base_name = os.path.splitext(file_name)[0]
        
        logger.info(f"ğŸš€ å¼€å§‹è°ƒè¯• Pipeline: {file_path}")
        logger.info("=" * 80)
        
        try:
            # æ­¥éª¤1: æ–‡æ¡£åŠ è½½è°ƒè¯•
            step1_result = self._debug_document_loading(file_path)
            
            # æ­¥éª¤2: æ–‡æ¡£åˆ†å—è°ƒè¯•
            step2_result = self._debug_chunking(step1_result["documents"])
            
            # æ­¥éª¤3: Embedding è°ƒè¯•
            step3_result = self._debug_embedding(step2_result["chunks"])
            
            # æ­¥éª¤4: Vector Store è°ƒè¯•
            step4_result = self._debug_vector_store(step3_result["embeddings"], step2_result["chunks"])
            
            # æ­¥éª¤5: æ¦‚å¿µæå–è°ƒè¯•
            step5_result = self._debug_concept_extraction(step2_result["chunks"])
            
            # æ­¥éª¤6: æ¦‚å¿µåˆå¹¶è°ƒè¯•
            step6_result = self._debug_concept_merging(step5_result["concepts"])
            
            # æ­¥éª¤7: è¯æ®æå–è°ƒè¯•
            step7_result = self._debug_evidence_extraction(step6_result["merged_concepts"], step2_result["chunks"])
            
            # æ­¥éª¤8: æ£€ç´¢è°ƒè¯•
            step8_result = self._debug_retrieval(step6_result["merged_concepts"], step4_result["vector_store"])
            
            # æ­¥éª¤9: é—®ç­”ç”Ÿæˆè°ƒè¯•
            step9_result = self._debug_qa_generation(step1_result["full_text"])
            
            # æ±‡æ€»æ‰€æœ‰ç»“æœ
            debug_results = {
                "file_info": {
                    "file_path": file_path,
                    "file_name": file_name,
                    "base_name": base_name,
                    "processing_time": (datetime.now() - start_time).total_seconds()
                },
                "step_results": {
                    "document_loading": step1_result,
                    "chunking": step2_result,
                    "embedding": step3_result,
                    "vector_store": step4_result,
                    "concept_extraction": step5_result,
                    "concept_merging": step6_result,
                    "evidence_extraction": step7_result,
                    "retrieval": step8_result,
                    "qa_generation": step9_result
                },
                "debug_info": self.debug_info,
                "timestamp": datetime.now().isoformat()
            }
            
            # ä¿å­˜è°ƒè¯•ç»“æœ
            self._save_debug_results(debug_results, base_name)
            
            # ç”Ÿæˆè°ƒè¯•æŠ¥å‘Š
            report_path, html_path = self._generate_debug_report(debug_results, base_name)
            
            logger.info(f"âœ… Pipeline è°ƒè¯•å®Œæˆ: {file_path}")
            return debug_results
            
        except Exception as e:
            logger.error(f"âŒ Pipeline è°ƒè¯•å¤±è´¥: {str(e)}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            self.debug_info["errors"].append({
                "step": "full_pipeline",
                "error": str(e),
                "traceback": traceback.format_exc(),
                "timestamp": datetime.now().isoformat()
            })
            return {"error": str(e), "debug_info": self.debug_info}
    
    def _debug_document_loading(self, file_path: str) -> Dict[str, Any]:
        """è°ƒè¯•æ–‡æ¡£åŠ è½½æ­¥éª¤"""
        step_start = datetime.now()
        logger.info("ğŸ“„ æ­¥éª¤1: è°ƒè¯•æ–‡æ¡£åŠ è½½...")
        
        try:
            # åŠ è½½æ–‡æ¡£
            documents = self.pipeline._load_document(file_path)
            full_text = "\n\n".join([doc.text for doc in documents])
            
            result = {
                "success": True,
                "documents_count": len(documents),
                "total_characters": len(full_text),
                "documents": documents,
                "full_text": full_text,
                "document_details": [
                    {
                        "index": i,
                        "text_length": len(doc.text),
                        "text_preview": doc.text[:200] + "..." if len(doc.text) > 200 else doc.text,
                        "metadata": doc.metadata
                    }
                    for i, doc in enumerate(documents)
                ],
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            
            # ä¿å­˜æ–‡æ¡£å†…å®¹
            self._save_step_result("01_document_loading", result, exclude_keys=["documents", "full_text"])
            
            logger.info(f"   âœ… æ–‡æ¡£åŠ è½½å®Œæˆ: {len(documents)} ä¸ªæ–‡æ¡£, {len(full_text)} å­—ç¬¦")
            return result
            
        except Exception as e:
            logger.error(f"   âŒ æ–‡æ¡£åŠ è½½å¤±è´¥: {str(e)}")
            result = {
                "success": False,
                "error": str(e),
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            self._save_step_result("01_document_loading", result)
            return result
    
    def _debug_chunking(self, documents: List[Document]) -> Dict[str, Any]:
        """è°ƒè¯•æ–‡æ¡£åˆ†å—æ­¥éª¤"""
        step_start = datetime.now()
        logger.info("âœ‚ï¸ æ­¥éª¤2: è°ƒè¯•æ–‡æ¡£åˆ†å—...")
        
        try:
            # ä½¿ç”¨ Pipeline çš„åˆ†å—å™¨
            chunker = self.pipeline.concept_pipeline.chunker
            chunks = []
            
            for doc in documents:
                doc_chunks = chunker.chunk_document(doc)
                chunks.extend(doc_chunks)
            
            result = {
                "success": True,
                "chunks_count": len(chunks),
                "chunks": chunks,
                "chunk_details": [
                    {
                        "index": i,
                        "node_id": chunk.node_id,
                        "text_length": len(chunk.text),
                        "text_preview": chunk.text[:200] + "..." if len(chunk.text) > 200 else chunk.text,
                        "metadata": chunk.metadata
                    }
                    for i, chunk in enumerate(chunks)
                ],
                "chunking_stats": {
                    "avg_chunk_length": sum(len(chunk.text) for chunk in chunks) / len(chunks) if chunks else 0,
                    "min_chunk_length": min(len(chunk.text) for chunk in chunks) if chunks else 0,
                    "max_chunk_length": max(len(chunk.text) for chunk in chunks) if chunks else 0
                },
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            
            self._save_step_result("02_chunking", result, exclude_keys=["chunks"])
            
            logger.info(f"   âœ… æ–‡æ¡£åˆ†å—å®Œæˆ: {len(chunks)} ä¸ªå—")
            return result
            
        except Exception as e:
            logger.error(f"   âŒ æ–‡æ¡£åˆ†å—å¤±è´¥: {str(e)}")
            result = {
                "success": False,
                "error": str(e),
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            self._save_step_result("02_chunking", result)
            return result
    
    def _debug_embedding(self, chunks: List) -> Dict[str, Any]:
        """è°ƒè¯• Embedding ç”Ÿæˆæ­¥éª¤"""
        step_start = datetime.now()
        logger.info("ğŸ”¢ æ­¥éª¤3: è°ƒè¯• Embedding ç”Ÿæˆ...")
        
        try:
            # ä½¿ç”¨ Pipeline çš„ embedding æ¨¡å‹
            embed_model = self.pipeline.concept_pipeline.vector_store_manager.embed_model
            
            embeddings = []
            embedding_details = []
            
            for i, chunk in enumerate(chunks[:5]):  # åªå¤„ç†å‰5ä¸ªå—ä½œä¸ºç¤ºä¾‹
                embedding = embed_model.get_text_embedding(chunk.text)
                embeddings.append(embedding)
                
                embedding_details.append({
                    "chunk_index": i,
                    "chunk_id": chunk.node_id,
                    "embedding_dimension": len(embedding),
                    "embedding_preview": embedding[:10],  # å‰10ä¸ªç»´åº¦
                    "embedding_norm": sum(x*x for x in embedding) ** 0.5
                })
            
            result = {
                "success": True,
                "embeddings_count": len(embeddings),
                "embeddings": embeddings,
                "embedding_details": embedding_details,
                "embedding_stats": {
                    "dimension": len(embeddings[0]) if embeddings else 0,
                    "avg_norm": sum(sum(x*x for x in emb) ** 0.5 for emb in embeddings) / len(embeddings) if embeddings else 0
                },
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            
            self._save_step_result("03_embedding", result, exclude_keys=["embeddings"])
            
            logger.info(f"   âœ… Embedding ç”Ÿæˆå®Œæˆ: {len(embeddings)} ä¸ªå‘é‡")
            return result
            
        except Exception as e:
            logger.error(f"   âŒ Embedding ç”Ÿæˆå¤±è´¥: {str(e)}")
            result = {
                "success": False,
                "error": str(e),
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            self._save_step_result("03_embedding", result)
            return result
    
    def _debug_vector_store(self, embeddings: List, chunks: List) -> Dict[str, Any]:
        """è°ƒè¯• Vector Store æ„å»ºæ­¥éª¤"""
        step_start = datetime.now()
        logger.info("ğŸ—„ï¸ æ­¥éª¤4: è°ƒè¯• Vector Store æ„å»º...")
        
        try:
            # ä½¿ç”¨ Pipeline çš„ vector store manager
            vector_store_manager = self.pipeline.concept_pipeline.vector_store_manager
            
            # æ„å»ºå‘é‡å­˜å‚¨
            vector_store = vector_store_manager.create_vector_store(chunks)
            
            result = {
                "success": True,
                "vector_store_type": type(vector_store).__name__,
                "stored_nodes_count": len(chunks),
                "vector_store": vector_store,
                "vector_store_stats": {
                    "total_vectors": len(chunks),
                    "vector_dimension": len(embeddings[0]) if embeddings else 0
                },
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            
            self._save_step_result("04_vector_store", result, exclude_keys=["vector_store"])
            
            logger.info(f"   âœ… Vector Store æ„å»ºå®Œæˆ: {len(chunks)} ä¸ªå‘é‡")
            return result
            
        except Exception as e:
            logger.error(f"   âŒ Vector Store æ„å»ºå¤±è´¥: {str(e)}")
            result = {
                "success": False,
                "error": str(e),
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            self._save_step_result("04_vector_store", result)
            return result
    
    def _debug_concept_extraction(self, chunks: List) -> Dict[str, Any]:
        """è°ƒè¯•æ¦‚å¿µæå–æ­¥éª¤"""
        step_start = datetime.now()
        logger.info("ğŸ§  æ­¥éª¤5: è°ƒè¯•æ¦‚å¿µæå–...")
        
        try:
            # ä½¿ç”¨ Pipeline çš„æ¦‚å¿µæå–å™¨
            concept_extractor = self.pipeline.concept_pipeline.concept_extractor
            
            concepts = []
            concept_details = []
            
            for i, chunk in enumerate(chunks):
                chunk_concepts = concept_extractor.extract_concepts_from_chunk(chunk)
                concepts.extend(chunk_concepts)
                
                concept_details.append({
                    "chunk_index": i,
                    "chunk_id": chunk.node_id,
                    "concepts_count": len(chunk_concepts),
                    "concepts": [
                        {
                            "concept_id": concept.node_id,
                            "concept_text": concept.text[:100] + "..." if len(concept.text) > 100 else concept.text,
                            "confidence": getattr(concept, 'confidence_score', 0.0)
                        }
                        for concept in chunk_concepts
                    ]
                })
            
            result = {
                "success": True,
                "concepts_count": len(concepts),
                "concepts": concepts,
                "concept_details": concept_details,
                "concept_stats": {
                    "avg_concepts_per_chunk": len(concepts) / len(chunks) if chunks else 0,
                    "total_concepts": len(concepts)
                },
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            
            self._save_step_result("05_concept_extraction", result, exclude_keys=["concepts"])
            
            logger.info(f"   âœ… æ¦‚å¿µæå–å®Œæˆ: {len(concepts)} ä¸ªæ¦‚å¿µ")
            return result
            
        except Exception as e:
            logger.error(f"   âŒ æ¦‚å¿µæå–å¤±è´¥: {str(e)}")
            result = {
                "success": False,
                "error": str(e),
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            self._save_step_result("05_concept_extraction", result)
            return result
    
    def _debug_concept_merging(self, concepts: List) -> Dict[str, Any]:
        """è°ƒè¯•æ¦‚å¿µåˆå¹¶æ­¥éª¤"""
        step_start = datetime.now()
        logger.info("ğŸ”— æ­¥éª¤6: è°ƒè¯•æ¦‚å¿µåˆå¹¶...")
        
        try:
            # ä½¿ç”¨ Pipeline çš„æ¦‚å¿µåˆå¹¶å™¨
            concept_merger = self.pipeline.concept_pipeline.concept_merger
            
            merged_concepts = concept_merger.merge_similar_concepts(concepts)
            
            result = {
                "success": True,
                "original_concepts_count": len(concepts),
                "merged_concepts_count": len(merged_concepts),
                "merged_concepts": merged_concepts,
                "merge_stats": {
                    "reduction_ratio": (len(concepts) - len(merged_concepts)) / len(concepts) if concepts else 0,
                    "concepts_before": len(concepts),
                    "concepts_after": len(merged_concepts)
                },
                "merge_details": [
                    {
                        "concept_id": concept.node_id,
                        "concept_text": concept.text[:100] + "..." if len(concept.text) > 100 else concept.text,
                        "source_chunks": getattr(concept, 'source_chunks', []),
                        "confidence": getattr(concept, 'confidence_score', 0.0)
                    }
                    for concept in merged_concepts
                ],
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            
            self._save_step_result("06_concept_merging", result, exclude_keys=["merged_concepts"])
            
            logger.info(f"   âœ… æ¦‚å¿µåˆå¹¶å®Œæˆ: {len(concepts)} -> {len(merged_concepts)} ä¸ªæ¦‚å¿µ")
            return result
            
        except Exception as e:
            logger.error(f"   âŒ æ¦‚å¿µåˆå¹¶å¤±è´¥: {str(e)}")
            result = {
                "success": False,
                "error": str(e),
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            self._save_step_result("06_concept_merging", result)
            return result
    
    def _debug_evidence_extraction(self, concepts: List, chunks: List) -> Dict[str, Any]:
        """è°ƒè¯•è¯æ®æå–æ­¥éª¤"""
        step_start = datetime.now()
        logger.info("ğŸ” æ­¥éª¤7: è°ƒè¯•è¯æ®æå–...")
        
        try:
            # ä½¿ç”¨ Pipeline çš„è¯æ®æå–å™¨
            evidence_extractor = self.pipeline.concept_pipeline.evidence_extractor
            
            evidence_nodes = []
            evidence_details = []
            
            for concept in concepts:
                concept_evidence = evidence_extractor.extract_evidence_for_concept(concept, chunks)
                evidence_nodes.extend(concept_evidence)
                
                evidence_details.append({
                    "concept_id": concept.node_id,
                    "concept_text": concept.text[:100] + "..." if len(concept.text) > 100 else concept.text,
                    "evidence_count": len(concept_evidence),
                    "evidence": [
                        {
                            "evidence_id": evidence.node_id,
                            "evidence_text": evidence.text[:100] + "..." if len(evidence.text) > 100 else evidence.text,
                            "relevance_score": getattr(evidence, 'relevance_score', 0.0)
                        }
                        for evidence in concept_evidence
                    ]
                })
            
            result = {
                "success": True,
                "evidence_count": len(evidence_nodes),
                "evidence_nodes": evidence_nodes,
                "evidence_details": evidence_details,
                "evidence_stats": {
                    "avg_evidence_per_concept": len(evidence_nodes) / len(concepts) if concepts else 0,
                    "total_evidence": len(evidence_nodes)
                },
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            
            self._save_step_result("07_evidence_extraction", result, exclude_keys=["evidence_nodes"])
            
            logger.info(f"   âœ… è¯æ®æå–å®Œæˆ: {len(evidence_nodes)} ä¸ªè¯æ®")
            return result
            
        except Exception as e:
            logger.error(f"   âŒ è¯æ®æå–å¤±è´¥: {str(e)}")
            result = {
                "success": False,
                "error": str(e),
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            self._save_step_result("07_evidence_extraction", result)
            return result
    
    def _debug_retrieval(self, concepts: List, vector_store) -> Dict[str, Any]:
        """è°ƒè¯•æ£€ç´¢æ­¥éª¤"""
        step_start = datetime.now()
        logger.info("ğŸ¯ æ­¥éª¤8: è°ƒè¯•æ£€ç´¢...")
        
        try:
            # ä½¿ç”¨ Pipeline çš„æ£€ç´¢å™¨
            retriever = self.pipeline.concept_pipeline.retriever
            
            retrieval_results = []
            
            # ä¸ºæ¯ä¸ªæ¦‚å¿µæ‰§è¡Œæ£€ç´¢
            for concept in concepts[:3]:  # åªæµ‹è¯•å‰3ä¸ªæ¦‚å¿µ
                query_results = retriever.retrieve_for_concept(concept, vector_store, top_k=5)
                
                retrieval_results.append({
                    "concept_id": concept.node_id,
                    "concept_text": concept.text[:100] + "..." if len(concept.text) > 100 else concept.text,
                    "retrieved_count": len(query_results),
                    "retrieved_chunks": [
                        {
                            "chunk_id": result.node.node_id,
                            "chunk_text": result.node.text[:100] + "..." if len(result.node.text) > 100 else result.node.text,
                            "similarity_score": result.score
                        }
                        for result in query_results
                    ]
                })
            
            result = {
                "success": True,
                "retrieval_results": retrieval_results,
                "retrieval_stats": {
                    "concepts_tested": len(retrieval_results),
                    "avg_retrieved_per_concept": sum(len(r["retrieved_chunks"]) for r in retrieval_results) / len(retrieval_results) if retrieval_results else 0
                },
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            
            self._save_step_result("08_retrieval", result)
            
            logger.info(f"   âœ… æ£€ç´¢æµ‹è¯•å®Œæˆ: æµ‹è¯•äº† {len(retrieval_results)} ä¸ªæ¦‚å¿µ")
            return result
            
        except Exception as e:
            logger.error(f"   âŒ æ£€ç´¢æµ‹è¯•å¤±è´¥: {str(e)}")
            result = {
                "success": False,
                "error": str(e),
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            self._save_step_result("08_retrieval", result)
            return result
    
    def _debug_qa_generation(self, full_text: str) -> Dict[str, Any]:
        """è°ƒè¯•é—®ç­”ç”Ÿæˆæ­¥éª¤"""
        step_start = datetime.now()
        logger.info("â“ æ­¥éª¤9: è°ƒè¯•é—®ç­”ç”Ÿæˆ...")
        
        try:
            # ä½¿ç”¨ Pipeline çš„é—®ç­”ç”Ÿæˆå™¨
            qa_generator = self.pipeline.qa_generator
            
            qa_pairs = qa_generator.generate_qa_pairs_from_text(full_text)
            
            result = {
                "success": True,
                "qa_pairs_count": len(qa_pairs),
                "qa_pairs": qa_pairs,
                "qa_details": [
                    {
                        "index": i,
                        "question": qa_pair.get("question", ""),
                        "answer": qa_pair.get("answer", "")[:200] + "..." if len(qa_pair.get("answer", "")) > 200 else qa_pair.get("answer", ""),
                        "question_type": qa_pair.get("question_type", ""),
                        "difficulty": qa_pair.get("difficulty", "")
                    }
                    for i, qa_pair in enumerate(qa_pairs)
                ],
                "qa_stats": {
                    "total_qa_pairs": len(qa_pairs),
                    "question_types": list(set(qa.get("question_type", "") for qa in qa_pairs)),
                    "avg_question_length": sum(len(qa.get("question", "")) for qa in qa_pairs) / len(qa_pairs) if qa_pairs else 0,
                    "avg_answer_length": sum(len(qa.get("answer", "")) for qa in qa_pairs) / len(qa_pairs) if qa_pairs else 0
                },
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            
            self._save_step_result("09_qa_generation", result)
            
            logger.info(f"   âœ… é—®ç­”ç”Ÿæˆå®Œæˆ: {len(qa_pairs)} ä¸ªé—®ç­”å¯¹")
            return result
            
        except Exception as e:
            logger.error(f"   âŒ é—®ç­”ç”Ÿæˆå¤±è´¥: {str(e)}")
            result = {
                "success": False,
                "error": str(e),
                "processing_time": (datetime.now() - step_start).total_seconds()
            }
            self._save_step_result("09_qa_generation", result)
            return result
    
    def _save_step_result(self, step_name: str, result: Dict[str, Any], exclude_keys: List[str] = None):
        """ä¿å­˜æ­¥éª¤ç»“æœåˆ°æ–‡ä»¶"""
        if exclude_keys is None:
            exclude_keys = []
        
        # åˆ›å»ºå¯åºåˆ—åŒ–çš„ç»“æœå‰¯æœ¬
        serializable_result = {}
        for key, value in result.items():
            if key not in exclude_keys:
                try:
                    json.dumps(value)  # æµ‹è¯•æ˜¯å¦å¯åºåˆ—åŒ–
                    serializable_result[key] = value
                except (TypeError, ValueError):
                    serializable_result[key] = str(value)  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        
        output_path = os.path.join(self.debug_output_dir, f"{step_name}.json")
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_result, f, ensure_ascii=False, indent=2)
        
        logger.info(f"   ğŸ’¾ æ­¥éª¤ç»“æœå·²ä¿å­˜: {output_path}")
    
    def _save_debug_results(self, debug_results: Dict[str, Any], base_name: str):
        """ä¿å­˜å®Œæ•´çš„è°ƒè¯•ç»“æœ"""
        output_path = os.path.join(self.debug_output_dir, f"{base_name}_debug_results.json")
        
        # åˆ›å»ºå¯åºåˆ—åŒ–çš„ç»“æœ
        serializable_results = {}
        for key, value in debug_results.items():
            try:
                json.dumps(value)
                serializable_results[key] = value
            except (TypeError, ValueError):
                serializable_results[key] = str(value)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(serializable_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ å®Œæ•´è°ƒè¯•ç»“æœå·²ä¿å­˜: {output_path}")
    
    def _generate_debug_report(self, debug_results: Dict[str, Any], base_name: str):
        """ç”Ÿæˆå¯è¯»çš„è°ƒè¯•æŠ¥å‘Š"""
        report_path = os.path.join(self.debug_output_dir, f"{base_name}_debug_report.md")
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"# Pipeline è°ƒè¯•æŠ¥å‘Š\n\n")
            f.write(f"**æ–‡ä»¶**: {debug_results['file_info']['file_name']}\n")
            f.write(f"**å¤„ç†æ—¶é—´**: {debug_results['file_info']['processing_time']:.2f} ç§’\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {debug_results['timestamp']}\n\n")
            
            f.write("## æ­¥éª¤æ¦‚è§ˆ\n\n")
            
            step_names = {
                "document_loading": "ğŸ“„ æ–‡æ¡£åŠ è½½",
                "chunking": "âœ‚ï¸ æ–‡æ¡£åˆ†å—", 
                "embedding": "ğŸ”¢ Embedding ç”Ÿæˆ",
                "vector_store": "ğŸ—„ï¸ Vector Store æ„å»º",
                "concept_extraction": "ğŸ§  æ¦‚å¿µæå–",
                "concept_merging": "ğŸ”— æ¦‚å¿µåˆå¹¶",
                "evidence_extraction": "ğŸ” è¯æ®æå–",
                "retrieval": "ğŸ¯ æ£€ç´¢æµ‹è¯•",
                "qa_generation": "â“ é—®ç­”ç”Ÿæˆ"
            }
            
            for step_key, step_name in step_names.items():
                step_result = debug_results["step_results"].get(step_key, {})
                status = "âœ… æˆåŠŸ" if step_result.get("success", False) else "âŒ å¤±è´¥"
                time_taken = step_result.get("processing_time", 0)
                
                f.write(f"- {step_name}: {status} ({time_taken:.2f}s)\n")
            
            f.write("\n## è¯¦ç»†ç»“æœ\n\n")
            
            # æ–‡æ¡£åŠ è½½è¯¦æƒ…
            doc_result = debug_results["step_results"].get("document_loading", {})
            if doc_result.get("success"):
                f.write(f"### ğŸ“„ æ–‡æ¡£åŠ è½½\n")
                f.write(f"- æ–‡æ¡£æ•°é‡: {doc_result.get('documents_count', 0)}\n")
                f.write(f"- æ€»å­—ç¬¦æ•°: {doc_result.get('total_characters', 0):,}\n\n")
            
            # åˆ†å—è¯¦æƒ…
            chunk_result = debug_results["step_results"].get("chunking", {})
            if chunk_result.get("success"):
                f.write(f"### âœ‚ï¸ æ–‡æ¡£åˆ†å—\n")
                f.write(f"- å—æ•°é‡: {chunk_result.get('chunks_count', 0)}\n")
                stats = chunk_result.get('chunking_stats', {})
                f.write(f"- å¹³å‡å—é•¿åº¦: {stats.get('avg_chunk_length', 0):.0f} å­—ç¬¦\n")
                f.write(f"- æœ€å°å—é•¿åº¦: {stats.get('min_chunk_length', 0)} å­—ç¬¦\n")
                f.write(f"- æœ€å¤§å—é•¿åº¦: {stats.get('max_chunk_length', 0)} å­—ç¬¦\n\n")
            
            # æ¦‚å¿µæå–è¯¦æƒ…
            concept_result = debug_results["step_results"].get("concept_extraction", {})
            if concept_result.get("success"):
                f.write(f"### ğŸ§  æ¦‚å¿µæå–\n")
                f.write(f"- æå–æ¦‚å¿µæ•°: {concept_result.get('concepts_count', 0)}\n")
                stats = concept_result.get('concept_stats', {})
                f.write(f"- å¹³å‡æ¯å—æ¦‚å¿µæ•°: {stats.get('avg_concepts_per_chunk', 0):.1f}\n\n")
            
            # æ¦‚å¿µåˆå¹¶è¯¦æƒ…
            merge_result = debug_results["step_results"].get("concept_merging", {})
            if merge_result.get("success"):
                f.write(f"### ğŸ”— æ¦‚å¿µåˆå¹¶\n")
                f.write(f"- åˆå¹¶å‰æ¦‚å¿µæ•°: {merge_result.get('original_concepts_count', 0)}\n")
                f.write(f"- åˆå¹¶åæ¦‚å¿µæ•°: {merge_result.get('merged_concepts_count', 0)}\n")
                stats = merge_result.get('merge_stats', {})
                f.write(f"- å‡å°‘æ¯”ä¾‹: {stats.get('reduction_ratio', 0):.1%}\n\n")
            
            # è¯æ®æå–è¯¦æƒ…
            evidence_result = debug_results["step_results"].get("evidence_extraction", {})
            if evidence_result.get("success"):
                f.write(f"### ğŸ” è¯æ®æå–\n")
                f.write(f"- è¯æ®æ•°é‡: {evidence_result.get('evidence_count', 0)}\n")
                stats = evidence_result.get('evidence_stats', {})
                f.write(f"- å¹³å‡æ¯æ¦‚å¿µè¯æ®æ•°: {stats.get('avg_evidence_per_concept', 0):.1f}\n\n")
            
            # é—®ç­”ç”Ÿæˆè¯¦æƒ…
            qa_result = debug_results["step_results"].get("qa_generation", {})
            if qa_result.get("success"):
                f.write(f"### â“ é—®ç­”ç”Ÿæˆ\n")
                f.write(f"- é—®ç­”å¯¹æ•°é‡: {qa_result.get('qa_pairs_count', 0)}\n")
                stats = qa_result.get('qa_stats', {})
                f.write(f"- é—®é¢˜ç±»å‹: {', '.join(stats.get('question_types', []))}\n")
                f.write(f"- å¹³å‡é—®é¢˜é•¿åº¦: {stats.get('avg_question_length', 0):.0f} å­—ç¬¦\n")
                f.write(f"- å¹³å‡ç­”æ¡ˆé•¿åº¦: {stats.get('avg_answer_length', 0):.0f} å­—ç¬¦\n\n")
        
        logger.info(f"ğŸ“Š è°ƒè¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        html_path = self.visualizer.generate_html_report(debug_results, base_name)
        return report_path, html_path


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨è°ƒè¯•å™¨"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Pipeline è°ƒè¯•å·¥å…·")
    parser.add_argument("--file", required=True, help="è¦è°ƒè¯•çš„æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--config", default="config/config.yml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", default="./debug_output", help="è°ƒè¯•è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºè°ƒè¯•å™¨
    debugger = PipelineDebugger(
        config_path=args.config,
        debug_output_dir=args.output
    )
    
    # æ‰§è¡Œè°ƒè¯•
    results = debugger.debug_full_pipeline(args.file)
    
    if "error" not in results:
        print(f"\nâœ… è°ƒè¯•å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {args.output}")
        print(f"ğŸ“Š æŸ¥çœ‹è°ƒè¯•æŠ¥å‘Š: {args.output}/{os.path.splitext(os.path.basename(args.file))[0]}_debug_report.md")
    else:
        print(f"\nâŒ è°ƒè¯•å¤±è´¥: {results['error']}")


if __name__ == "__main__":
    main() 