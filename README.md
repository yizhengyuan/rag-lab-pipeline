# ConceptBasedPipeline - åŸºäºæ¦‚å¿µçš„é—®é¢˜ç”Ÿæˆç®¡é“

## é¡¹ç›®ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªåŸºäº LlamaIndex æ¡†æ¶å®ç°çš„å¤šé˜¶æ®µé—®é¢˜ç”Ÿæˆ Pipelineï¼Œå‚è€ƒäº† Savaal çš„ 3-stage æ€è·¯ï¼Œä¸“æ³¨äºå®ç°å‰4ä¸ªæ ¸å¿ƒæ­¥éª¤ï¼š

1. **Semantic Chunking + Chunk-Level-Concepts æå–**
2. **Document-Level-Concept åˆå¹¶å’Œåå¤„ç†**  
3. **åŸºäº Doc-Concept çš„ç›¸å…³ chunks æ£€ç´¢**
4. **Evidence æå–**

## æ ¸å¿ƒç‰¹æ€§

ğŸ” **æ™ºèƒ½è¯­ä¹‰åˆ†å—**: ä½¿ç”¨ LlamaIndex çš„ SemanticSplitterNodeParser è¿›è¡Œè¯­ä¹‰æ„ŸçŸ¥çš„æ–‡æ¡£åˆ†å—

ğŸ§  **æ¦‚å¿µæå–**: ä»æ¯ä¸ª chunk ä¸­æå–æ ¸å¿ƒæ¦‚å¿µï¼Œæ”¯æŒå…³é”®è¯å’ŒçŸ­å¥å½¢å¼

ğŸ”— **æ¦‚å¿µåˆå¹¶**: ä½¿ç”¨ç›¸ä¼¼æ€§èšç±»å°†ç›¸å…³æ¦‚å¿µåˆå¹¶ä¸ºæ–‡æ¡£çº§åˆ«æ¦‚å¿µ

ğŸ¯ **ç²¾å‡†æ£€ç´¢**: åŸºäºæ–‡æ¡£æ¦‚å¿µè¿›è¡Œè·¨chunkçš„ç›¸å…³å†…å®¹æ£€ç´¢

ğŸ’¡ **è¯æ®æå–**: ä»æ£€ç´¢ç»“æœä¸­æå–é«˜è´¨é‡çš„è¯æ®ç‰‡æ®µï¼Œå»é™¤å™ªå£°

## å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

## ğŸ“ æ”¯æŒçš„æ–‡æ¡£æ ¼å¼

LlamaIndex åŸç”Ÿæ”¯æŒå¤šç§æ–‡æ¡£æ ¼å¼ï¼Œæ— éœ€é¢å¤–é…ç½®ï¼š

- âœ… **PDF æ–‡æ¡£** (.pdf) - è‡ªåŠ¨æ–‡æœ¬æå–
- âœ… **æ–‡æœ¬æ–‡ä»¶** (.txt, .md) 
- âœ… **Word æ–‡æ¡£** (.docx)
- âœ… **ç½‘é¡µå†…å®¹** (.html)

### PDF æ–‡æ¡£ä½¿ç”¨ç¤ºä¾‹

```python
from llama_index.core import SimpleDirectoryReader

# ä»ç›®å½•æ‰¹é‡åŠ è½½ PDF
reader = SimpleDirectoryReader(input_dir="./pdfs/", required_exts=[".pdf"])
documents = reader.load_data()

# æˆ–æŒ‡å®šç‰¹å®š PDF æ–‡ä»¶
reader = SimpleDirectoryReader(input_files=["paper.pdf", "report.pdf"])
documents = reader.load_data()

# è¿è¡Œ pipeline
pipeline = ConceptBasedPipeline(openai_api_key="your-api-key")
results = pipeline.run_pipeline(documents)
```

è¿è¡Œ PDF ä¸“ç”¨ç¤ºä¾‹ï¼š
```bash
python pdf_example.py
```

## å¿«é€Ÿå¼€å§‹

### 1. é…ç½® API å¯†é’¥

```python
# è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="your-api-key-here"
```

### 2. è¿è¡Œç¤ºä¾‹

```bash
python example_usage.py
```

### 3. åŸºæœ¬ä½¿ç”¨

```python
from llama_index.core import Document
from pipeline import ConceptBasedPipeline

# åˆå§‹åŒ– pipeline
pipeline = ConceptBasedPipeline(openai_api_key="your-api-key")

# å‡†å¤‡æ–‡æ¡£
documents = [Document(text="æ‚¨çš„æ–‡æ¡£å†…å®¹")]

# è¿è¡Œå®Œæ•´ pipeline
results = pipeline.run_pipeline(documents)

# ä¿å­˜ç»“æœ
pipeline.save_results(results, "output.json")
```

## æŠ€æœ¯æ¶æ„

```
è¾“å…¥æ–‡æ¡£ â†’ Semantic Chunking â†’ Concept æå– â†’ æ¦‚å¿µåˆå¹¶ â†’ æ¦‚å¿µæ£€ç´¢ â†’ Evidence æå–
```

## ğŸ“ é…ç½®ç®¡ç†

### YAML é…ç½®ç³»ç»Ÿ

é¡¹ç›®ä½¿ç”¨ YAML æ ¼å¼è¿›è¡Œé…ç½®ç®¡ç†ï¼Œæä¾›æ›´å¥½çš„å¯è¯»æ€§å’Œçµæ´»æ€§ï¼š

**ä¸»é…ç½®æ–‡ä»¶**: `config.yml`

```yaml
# OpenAI è®¾ç½®
openai:
  api_key: "your-openai-api-key-here"
  model: "gpt-3.5-turbo"
  embedding_model: "text-embedding-ada-002"
  temperature: 0.1

# æ¦‚å¿µåˆå¹¶è®¾ç½®
concept_merging:
  similarity_threshold: 0.7  # æ¦‚å¿µç›¸ä¼¼æ€§é˜ˆå€¼
  max_document_concepts: 10  # æœ€å¤§æ–‡æ¡£æ¦‚å¿µæ•°é‡

# æ£€ç´¢è®¾ç½®
retrieval:
  top_k: 5  # æ£€ç´¢çš„ chunk æ•°é‡

# Evidence æå–è®¾ç½®
evidence_extraction:
  min_length: 20   # æœ€å°è¯æ®é•¿åº¦
  max_length: 200  # æœ€å¤§è¯æ®é•¿åº¦
```

### é…ç½®åŠ è½½å’Œä½¿ç”¨

```python
from config_loader import load_config

# åŠ è½½é…ç½®
config = load_config("config.yml")

# ä½¿ç”¨é…ç½®
pipeline = ConceptBasedPipeline(
    openai_api_key=config.openai.api_key,
    model_name=config.openai.model
)
```

### ç¯å¢ƒå˜é‡è¦†ç›–

æ”¯æŒä½¿ç”¨ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®ï¼š

```bash
export OPENAI_API_KEY="your-key"
export OPENAI_MODEL="gpt-4"
export CONCEPT_SIMILARITY_THRESHOLD="0.8"
```

### å¤šç¯å¢ƒé…ç½®

```bash
# è¿è¡Œé…ç½®æ¼”ç¤ºï¼Œç”Ÿæˆä¸åŒç¯å¢ƒçš„é…ç½®æ–‡ä»¶
python config_example.py

# ä½¿ç”¨ç‰¹å®šç¯å¢ƒé…ç½®
python your_script.py --config config_dev.yml  # å¼€å‘ç¯å¢ƒ
python your_script.py --config config_prod.yml # ç”Ÿäº§ç¯å¢ƒ
```

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
llamaindex-pipeline/
â”œâ”€â”€ ğŸ”§ é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config.yml              # ä¸»é…ç½®æ–‡ä»¶ (YAML)
â”‚   â”œâ”€â”€ config_loader.py        # YAML é…ç½®åŠ è½½å™¨
â”‚   â”œâ”€â”€ config_dev.yml          # å¼€å‘ç¯å¢ƒé…ç½®
â”‚   â”œâ”€â”€ config_prod.yml         # ç”Ÿäº§ç¯å¢ƒé…ç½®
â”‚   â””â”€â”€ config.py               # åŸé…ç½®æ–‡ä»¶ (å·²åºŸå¼ƒ)
â”‚
â”œâ”€â”€ ğŸš€ æ ¸å¿ƒ Pipeline
â”‚   â”œâ”€â”€ pipeline.py             # ä¸» Pipeline å®ç°
â”‚   â””â”€â”€ pipeline_improved.py    # æ”¹è¿›ç‰ˆ Pipeline
â”‚
â”œâ”€â”€ ğŸ“– ä½¿ç”¨ç¤ºä¾‹
â”‚   â”œâ”€â”€ example_usage.py        # åŸºç¡€ä½¿ç”¨ç¤ºä¾‹
â”‚   â”œâ”€â”€ pdf_example.py          # PDF å¤„ç†ç¤ºä¾‹
â”‚   â”œâ”€â”€ demo_with_pdf.py        # PDF æ¼”ç¤ºè„šæœ¬
â”‚   â””â”€â”€ config_example.py       # é…ç½®ç³»ç»Ÿæ¼”ç¤º
â”‚
â”œâ”€â”€ ğŸ§ª æµ‹è¯•æ–‡ä»¶
â”‚   â”œâ”€â”€ test_pipeline.py        # æ¨¡æ‹Ÿæµ‹è¯•
â”‚   â””â”€â”€ test_no_api.py          # æ—  API æµ‹è¯•
â”‚
â”œâ”€â”€ ğŸ“„ æ–‡æ¡£
â”‚   â”œâ”€â”€ README.md               # é¡¹ç›®è¯´æ˜
â”‚   â”œâ”€â”€ environment_setup.md    # ç¯å¢ƒé…ç½®
â”‚   â””â”€â”€ requirements.txt        # ä¾èµ–åˆ—è¡¨
â”‚
â””â”€â”€ ğŸ“Š ç¤ºä¾‹æ•°æ®
    â””â”€â”€ attention is all you need.pdf  # ç¤ºä¾‹ PDF æ–‡æ¡£
```

## ğŸ†• æ–°åŠŸèƒ½ç‰¹æ€§

### âœ… YAML é…ç½®ç³»ç»Ÿ
- ğŸ“ å¯è§†åŒ–é…ç½®ç¼–è¾‘
- ğŸ”„ ç¯å¢ƒå˜é‡è¦†ç›–
- ğŸŒ å¤šç¯å¢ƒæ”¯æŒ
- ğŸ”’ é…ç½®éªŒè¯

### âœ… PDF æ–‡æ¡£æ”¯æŒ
- ğŸ“„ åŸç”Ÿ PDF å¤„ç†
- ğŸ“š æ‰¹é‡æ–‡æ¡£åŠ è½½
- ğŸ” è‡ªåŠ¨æ–‡æœ¬æå–

### âœ… æ”¹è¿›ç‰ˆ Pipeline
- ğŸ§  æ›´å¥½çš„ LlamaIndex é›†æˆ
- ğŸš€ ä¼˜åŒ–çš„æ€§èƒ½
- ğŸ“Š è¯¦ç»†çš„ç»“æœè¾“å‡º

## ä¾èµ–ç‰ˆæœ¬

- Python >= 3.8
- llama-index >= 0.10.0
- openai >= 1.12.0
- sentence-transformers >= 2.2.0
- PyYAML >= 6.0

## è®¸å¯è¯

MIT License 