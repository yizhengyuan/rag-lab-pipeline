"""
æœ¬åœ°å‘é‡æ•°æ®åº“æµ‹è¯•è„šæœ¬
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ Chroma æœ¬åœ°å­˜å‚¨ embeddingï¼Œé¿å…é‡å¤è°ƒç”¨ OpenAI API

ä½¿ç”¨æ–¹æ³•ï¼š
1. å®‰è£…æ–°ä¾èµ–ï¼špip install chromadb llama-index-vector-stores-chroma
2. ç¡®ä¿ config.yml ä¸­ vector_store.type è®¾ä¸º "chroma"
3. è¿è¡Œæ­¤è„šæœ¬
"""

import os
import sys
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from core.chunking import SemanticChunker, EmbeddingCache
from core.vector_store import VectorStoreManager
from utils.config_loader import ConfigLoader
from llama_index.core import Document

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_local_vector_store():
    """æµ‹è¯•æœ¬åœ°å‘é‡å­˜å‚¨åŠŸèƒ½"""
    
    print("ğŸš€ å¼€å§‹æµ‹è¯•æœ¬åœ°å‘é‡æ•°æ®åº“åŠŸèƒ½...")
    
    # 1. åŠ è½½é…ç½®
    try:
        config = ConfigLoader.load_config()
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
        print(f"ğŸ“‚ å‘é‡æ•°æ®åº“ç±»å‹: {config.get('vector_store.type')}")
        print(f"ğŸ“‚ å­˜å‚¨è·¯å¾„: {config.get('vector_store.persist_directory')}")
        print(f"ğŸ”§ ç¼“å­˜å¯ç”¨: {config.get('vector_store.enable_embedding_cache')}")
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 2. æ£€æŸ¥å‘é‡æ•°æ®åº“é…ç½®
    vector_store_type = config.get('vector_store.type', 'simple')
    if vector_store_type != 'chroma':
        print(f"âš ï¸  å½“å‰å‘é‡å­˜å‚¨ç±»å‹ä¸º: {vector_store_type}")
        print("ğŸ’¡ å»ºè®®åœ¨ config.yml ä¸­è®¾ç½® vector_store.type: 'chroma' ä»¥å¯ç”¨æœ¬åœ°å­˜å‚¨")
    
    # 3. åˆå§‹åŒ–ç»„ä»¶
    try:
        print("\nğŸ”§ åˆå§‹åŒ–ç»„ä»¶...")
        
        # åˆå§‹åŒ–è¯­ä¹‰åˆ†å—å™¨ï¼ˆåŒ…å«embeddingç¼“å­˜ï¼‰
        chunker = SemanticChunker(config)
        
        # åˆå§‹åŒ–å‘é‡å­˜å‚¨ç®¡ç†å™¨
        vector_manager = VectorStoreManager(config)
        
        print("âœ… ç»„ä»¶åˆå§‹åŒ–æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
        return False
    
    # 4. åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    test_documents = [
        Document(
            text="äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä¼å›¾äº†è§£æ™ºèƒ½çš„å®è´¨ï¼Œå¹¶ç”Ÿäº§å‡ºä¸€ç§æ–°çš„èƒ½ä»¥äººç±»æ™ºèƒ½ç›¸ä¼¼çš„æ–¹å¼åšå‡ºååº”çš„æ™ºèƒ½æœºå™¨ã€‚"
        ),
        Document(
            text="æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒæ¨¡æ‹Ÿäººè„‘çš„ç¥ç»ç½‘ç»œç»“æ„ï¼Œé€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ æ•°æ®çš„è¡¨ç¤ºã€‚"
        ),
        Document(
            text="è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œæ—¨åœ¨è®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£ã€è§£é‡Šå’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚"
        )
    ]
    
    print(f"\nğŸ“ åˆ›å»ºäº† {len(test_documents)} ä¸ªæµ‹è¯•æ–‡æ¡£")
    
    # 5. ç¬¬ä¸€æ¬¡å¤„ç†ï¼ˆä¼šè°ƒç”¨APIå¹¶ç¼“å­˜ï¼‰
    print("\nğŸ”„ ç¬¬ä¸€æ¬¡å¤„ç†æ–‡æ¡£ï¼ˆä¼šè°ƒç”¨ OpenAI APIï¼‰...")
    try:
        chunk_nodes = chunker.chunk_and_extract_concepts(test_documents)
        print(f"âœ… åˆ†å—å®Œæˆ: {len(chunk_nodes)} ä¸ª chunks")
        
        # æ˜¾ç¤ºæ¦‚å¿µæå–ç»“æœ
        for i, node in enumerate(chunk_nodes[:2]):  # åªæ˜¾ç¤ºå‰2ä¸ª
            concepts = chunker.get_concepts_from_node(node)  # ğŸ”‘ ä½¿ç”¨æ–°æ–¹æ³•è·å–concepts
            print(f"ğŸ“ Chunk {i+1}: {len(concepts)} ä¸ªæ¦‚å¿µ - {concepts}")
        
    except Exception as e:
        print(f"âŒ ç¬¬ä¸€æ¬¡å¤„ç†å¤±è´¥: {e}")
        return False
    
    # 6. æ˜¾ç¤ºç¼“å­˜ç»Ÿè®¡
    if chunker.embedding_cache:
        cache_stats = chunker.embedding_cache.get_cache_stats()
        print(f"\nğŸ’¾ Embeddingç¼“å­˜ç»Ÿè®¡:")
        print(f"   ğŸ“Š ç¼“å­˜æ¡ç›®: {cache_stats['total_entries']}")
        print(f"   ğŸ’½ ä¼°ç®—å¤§å°: {cache_stats['estimated_size_mb']:.2f} MB")
        print(f"   ğŸ“‚ ç¼“å­˜ç›®å½•: {cache_stats['cache_directory']}")
    
    # 7. åˆ›å»ºå‘é‡ç´¢å¼•å¹¶æŒä¹…åŒ–
    try:
        print(f"\nğŸ—ƒï¸  åˆ›å»ºå‘é‡ç´¢å¼•...")
        chunk_index = vector_manager.create_chunk_index(chunk_nodes, persist=True)
        print(f"âœ… å‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸï¼Œå·²æŒä¹…åŒ–åˆ°æœ¬åœ°")
        
    except Exception as e:
        print(f"âŒ å‘é‡ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # 8. é‡ç½®å¹¶æµ‹è¯•ç¬¬äºŒæ¬¡å¤„ç†ï¼ˆåº”è¯¥ä½¿ç”¨ç¼“å­˜ï¼‰
    print(f"\nğŸ”„ é‡ç½®åç¬¬äºŒæ¬¡å¤„ç†ï¼ˆåº”è¯¥ä½¿ç”¨ç¼“å­˜ï¼‰...")
    try:
        chunker.reset()
        
        # ç¬¬äºŒæ¬¡å¤„ç†ç›¸åŒæ–‡æ¡£
        start_time = time.time() if 'time' in globals() else None
        chunk_nodes_2 = chunker.chunk_and_extract_concepts(test_documents)
        
        print(f"âœ… ç¬¬äºŒæ¬¡å¤„ç†å®Œæˆ: {len(chunk_nodes_2)} ä¸ª chunks")
        
        if chunker.embedding_cache:
            cache_stats_2 = chunker.embedding_cache.get_cache_stats()
            print(f"ğŸ’¾ ç¼“å­˜å‘½ä¸­æƒ…å†µ: {cache_stats_2['total_entries']} æ¡ç¼“å­˜è®°å½•")
        
    except Exception as e:
        print(f"âŒ ç¬¬äºŒæ¬¡å¤„ç†å¤±è´¥: {e}")
    
    # 9. æ˜¾ç¤ºå‘é‡æ•°æ®åº“ä¿¡æ¯
    try:
        print(f"\nğŸ“‹ å‘é‡æ•°æ®åº“ä¿¡æ¯:")
        index_info = vector_manager.get_index_info()
        
        for index_type, info in index_info['indexes'].items():
            if info['exists'] or info['persisted']:
                print(f"   ğŸ“ {index_type}: å­˜åœ¨={info['exists']}, æŒä¹…åŒ–={info['persisted']}")
                if info['metadata'].get('node_count', 0) > 0:
                    print(f"      ğŸ“Š èŠ‚ç‚¹æ•°: {info['metadata']['node_count']}")
                    print(f"      ğŸ• æ›´æ–°æ—¶é—´: {info['metadata'].get('last_updated', 'N/A')}")
        
        # æ˜¾ç¤ºå­˜å‚¨å¤§å°
        storage_info = vector_manager.get_storage_size()
        print(f"   ğŸ’½ æ€»å­˜å‚¨å¤§å°: {storage_info['total_size_mb']:.2f} MB")
        
    except Exception as e:
        print(f"âš ï¸  è·å–å‘é‡æ•°æ®åº“ä¿¡æ¯å¤±è´¥: {e}")
    
    print(f"\nâœ… æœ¬åœ°å‘é‡æ•°æ®åº“æµ‹è¯•å®Œæˆï¼")
    print(f"\nğŸ’¡ ä¸»è¦ä¼˜åŠ¿:")
    print(f"   ğŸš€ é¦–æ¬¡å¤„ç†åï¼Œembedding å·²ä¿å­˜åˆ°æœ¬åœ°")
    print(f"   ğŸ’° åç»­ç›¸åŒæ–‡æ¡£å¤„ç†å°†ä½¿ç”¨ç¼“å­˜ï¼ŒèŠ‚çœ API è´¹ç”¨")
    print(f"   âš¡ å¤§å¹…æå‡å¤„ç†é€Ÿåº¦")
    print(f"   ğŸ”’ æ•°æ®å®Œå…¨å­˜å‚¨åœ¨æœ¬åœ°ï¼Œä¿æŠ¤éšç§")
    
    return True

def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–æ˜¯å¦å·²å®‰è£…"""
    
    print("ğŸ” æ£€æŸ¥ä¾èµ–...")
    
    missing_deps = []
    
    try:
        import chromadb
        print("âœ… chromadb å·²å®‰è£…")
    except ImportError:
        missing_deps.append("chromadb")
    
    try:
        from llama_index.vector_stores.chroma import ChromaVectorStore
        print("âœ… llama-index-vector-stores-chroma å·²å®‰è£…")
    except ImportError:
        missing_deps.append("llama-index-vector-stores-chroma")
    
    if missing_deps:
        print(f"\nâŒ ç¼ºå°‘ä¾èµ–: {', '.join(missing_deps)}")
        print(f"è¯·è¿è¡Œ: pip install {' '.join(missing_deps)}")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
    return True

if __name__ == "__main__":
    print("ğŸ¯ æœ¬åœ°å‘é‡æ•°æ®åº“æµ‹è¯•å·¥å…·")
    print("=" * 50)
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        sys.exit(1)
    
    # è¿è¡Œæµ‹è¯•
    try:
        import time  # ç”¨äºè®¡æ—¶
        success = test_local_vector_store()
        if success:
            print("\nğŸ‰ æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥")
            sys.exit(1)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ’¥ æµ‹è¯•å‡ºç°å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1) 